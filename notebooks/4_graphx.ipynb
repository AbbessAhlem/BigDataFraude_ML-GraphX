{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c737d2-3e7a-4f23-b690-e72b39b80dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphframes\n",
      "  Downloading graphframes-0.6-py2.py3-none-any.whl.metadata (934 bytes)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from graphframes) (1.24.4)\n",
      "Collecting nose (from graphframes)\n",
      "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
      "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: nose, graphframes\n",
      "Successfully installed graphframes-0.6 nose-1.3.7\n",
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.11/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphframes\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565ca80b-37a0-4f76-9996-8a803d499cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chargement des donn√©es originales ---\n",
      "Nombre total de transactions : 284807\n",
      "root\n",
      " |-- Time: double (nullable = true)\n",
      " |-- V1: double (nullable = true)\n",
      " |-- V2: double (nullable = true)\n",
      " |-- V3: double (nullable = true)\n",
      " |-- V4: double (nullable = true)\n",
      " |-- V5: double (nullable = true)\n",
      " |-- V6: double (nullable = true)\n",
      " |-- V7: double (nullable = true)\n",
      " |-- V8: double (nullable = true)\n",
      " |-- V9: double (nullable = true)\n",
      " |-- V10: double (nullable = true)\n",
      " |-- V11: double (nullable = true)\n",
      " |-- V12: double (nullable = true)\n",
      " |-- V13: double (nullable = true)\n",
      " |-- V14: double (nullable = true)\n",
      " |-- V15: double (nullable = true)\n",
      " |-- V16: double (nullable = true)\n",
      " |-- V17: double (nullable = true)\n",
      " |-- V18: double (nullable = true)\n",
      " |-- V19: double (nullable = true)\n",
      " |-- V20: double (nullable = true)\n",
      " |-- V21: double (nullable = true)\n",
      " |-- V22: double (nullable = true)\n",
      " |-- V23: double (nullable = true)\n",
      " |-- V24: double (nullable = true)\n",
      " |-- V25: double (nullable = true)\n",
      " |-- V26: double (nullable = true)\n",
      " |-- V27: double (nullable = true)\n",
      " |-- V28: double (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Initialisation Spark et Chargement\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, sum as spark_sum, coalesce\n",
    "from pyspark.sql.window import Window\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "# Configuration Spark (pour l'environnement HDFS et GraphFrames)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud-GraphX-Analysis-Final\") \\\n",
    "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Chemin de base HDFS\n",
    "hdfs_base_path = \"hdfs://namenode:8020/data\"\n",
    "\n",
    "# Chargement du jeu de donn√©es original (comme confirm√© pr√©c√©demment)\n",
    "print(\"--- Chargement des donn√©es originales ---\")\n",
    "try:\n",
    "    df = spark.read.csv(\n",
    "        f\"{hdfs_base_path}/creditcard.csv\", \n",
    "        header=True, \n",
    "        inferSchema=True\n",
    "    )\n",
    "    df.cache()\n",
    "    print(f\"Nombre total de transactions : {df.count()}\")\n",
    "    df.printSchema()\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR DE CHARGEMENT : {e}\")\n",
    "    # Ajoutez ici un chemin de secours si le HDFS n'est pas accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb54aba-476e-4bfc-92d4-79af75816567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cr√©ation des Vertices (Clients V1) ---\n",
      "Nombre de n≈ìuds uniques (V1) : 275663\n",
      "+----------------+-----+------+--------+\n",
      "|              id|label|Amount|pagerank|\n",
      "+----------------+-----+------+--------+\n",
      "|-1.2768303373631|    0| 110.4|     1.0|\n",
      "|1.21205680491093|    0|  2.28|     1.0|\n",
      "|1.08102680841932|    0| 17.24|     1.0|\n",
      "|1.49157444507907|    0|   2.0|     1.0|\n",
      "|1.09337038677875|    0|  49.9|     1.0|\n",
      "+----------------+-----+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 2/8 : Cr√©ation des Vertices (N≈ìuds)\n",
    "print(\"--- Cr√©ation des Vertices (Clients V1) ---\")\n",
    "\n",
    "# Les N≈ìuds sont les identifiants V1 uniques\n",
    "vertices_final = df.select(\n",
    "    col(\"V1\").alias(\"id\"),  \n",
    "    col(\"Class\").alias(\"label\"),\n",
    "    col(\"Amount\")\n",
    ").distinct()\n",
    "\n",
    "# La colonne 'label' doit √™tre num√©rique (0 ou 1) pour les calculs.\n",
    "vertices_final = vertices_final.withColumn(\"label\", col(\"label\").cast(\"int\"))\n",
    "\n",
    "# Le PageRank initial (sera r√©initialis√© plus tard)\n",
    "vertices_final = vertices_final.withColumn(\"pagerank\", lit(1.0))\n",
    "vertices_final.cache()\n",
    "\n",
    "print(f\"Nombre de n≈ìuds uniques (V1) : {vertices_final.count()}\")\n",
    "vertices_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db571b76-e2f5-418b-85d1-be577da39d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cr√©ation des Edges (Liens Frauduleux Co-occurrents) ---\n",
      "Nombre total d'ar√™tes (liens de fraude) : 7016\n",
      "+-----------------+-----------------+\n",
      "|              src|              dst|\n",
      "+-----------------+-----------------+\n",
      "|0.314596589729515|-1.58550536691994|\n",
      "|-4.72771265581559|-2.58961719821269|\n",
      "|-16.5986647432584|-25.2663550194138|\n",
      "|-19.8563223334433|  -27.84818067198|\n",
      "|-2.78724793061533|  -27.84818067198|\n",
      "+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 3/8 : Cr√©ation des Edges (Liens Frauduleux Co-occurrents)\n",
    "print(\"--- Cr√©ation des Edges (Liens Frauduleux Co-occurrents) ---\")\n",
    "\n",
    "edges = df.alias(\"t1\").join(\n",
    "    df.alias(\"t2\"),\n",
    "    (\n",
    "        # 1. Les deux sont des fraudes\n",
    "        (col(\"t1.Class\") == 1) & (col(\"t2.Class\") == 1) &\n",
    "        \n",
    "        # 2. Elles se produisent dans la m√™me heure\n",
    "        ((col(\"t1.Time\") / 3600).cast(\"int\") == (col(\"t2.Time\") / 3600).cast(\"int\")) &\n",
    "        \n",
    "        # 3. Ce sont des entit√©s/clients diff√©rents (src != dst)\n",
    "        (col(\"t1.V1\") != col(\"t2.V1\"))\n",
    "    )\n",
    ").select(\n",
    "    col(\"t1.V1\").alias(\"src\"),\n",
    "    col(\"t2.V1\").alias(\"dst\")\n",
    ").distinct()\n",
    "\n",
    "edges.cache()\n",
    "print(f\"Nombre total d'ar√™tes (liens de fraude) : {edges.count()}\")\n",
    "edges.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0005d2-f742-4493-af1d-6edd2feed00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "--- V√©rification et Ajustement du Sch√©ma pour GraphFrame ---\n",
      "======================================================================\n",
      "\n",
      "üîÑ Converting IDs to string format...\n",
      "‚úÖ Vertices: 275,663 nodes\n",
      "‚úÖ Edges: 7,016 connections\n",
      "\n",
      "üî® Creating GraphFrame...\n",
      "‚úÖ GraphFrame cr√©√© avec succ√®s!\n",
      "\n",
      "======================================================================\n",
      "--- Analyse des Degr√©s (Degree Centrality) ---\n",
      "======================================================================\n",
      "\n",
      "üìä Top 5 des N≈ìuds (V1) les plus connect√©s (Degr√©):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n",
      "/usr/local/spark/python/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|               id|degree|\n",
      "+-----------------+------+\n",
      "|-10.6457996485752|    84|\n",
      "|-5.31417320646342|    84|\n",
      "|-16.5265065691231|    84|\n",
      "|-2.14441147422114|    84|\n",
      "|-3.14025953779538|    84|\n",
      "+-----------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üìà Statistiques des degr√©s:\n",
      "+-------+------------------+\n",
      "|summary|            degree|\n",
      "+-------+------------------+\n",
      "|  count|               472|\n",
      "|   mean|29.728813559322035|\n",
      "| stddev|20.826106846996957|\n",
      "|    min|                 2|\n",
      "|    max|                84|\n",
      "+-------+------------------+\n",
      "\n",
      "\n",
      "üìä Distribution des degr√©s:\n",
      "+------+-----+\n",
      "|degree|count|\n",
      "+------+-----+\n",
      "|    84|   43|\n",
      "|    26|   42|\n",
      "|    14|   40|\n",
      "|    18|   40|\n",
      "|    24|   39|\n",
      "|    22|   36|\n",
      "|    52|   27|\n",
      "|    10|   24|\n",
      "|    44|   23|\n",
      "|    40|   21|\n",
      "+------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üîç N≈ìuds isol√©s (degree = 1): 0\n",
      "üö® N≈ìuds hautement connect√©s (degree > 50): 70\n",
      "\n",
      "Exemples de hubs:\n",
      "+------------------+------+\n",
      "|                id|degree|\n",
      "+------------------+------+\n",
      "|-0.964567282813312|    84|\n",
      "| -13.8972058704019|    84|\n",
      "| -2.52401156950864|    84|\n",
      "| -5.31417320646342|    84|\n",
      "| -7.33434102050082|    84|\n",
      "| -2.37753280180283|    84|\n",
      "| -7.89688615307576|    84|\n",
      "| -10.6457996485752|    84|\n",
      "| -3.84300903438536|    84|\n",
      "| -3.14025953779538|    84|\n",
      "+------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cellule 4/8 : Cr√©ation du GraphFrame et Analyse Structurale\n",
    "from pyspark.sql.functions import col, desc, count as spark_count, avg\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"--- V√©rification et Ajustement du Sch√©ma pour GraphFrame ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Conversion des IDs en String (Obligatoire pour GraphFrames)\n",
    "print(\"\\nüîÑ Converting IDs to string format...\")\n",
    "vertices = vertices_final.withColumn(\"id\", col(\"id\").cast(\"string\"))\n",
    "edges = edges.withColumn(\"src\", col(\"src\").cast(\"string\")) \\\n",
    "             .withColumn(\"dst\", col(\"dst\").cast(\"string\"))\n",
    "\n",
    "# V√©rification\n",
    "print(f\"‚úÖ Vertices: {vertices.count():,} nodes\")\n",
    "print(f\"‚úÖ Edges: {edges.count():,} connections\")\n",
    "\n",
    "# 2. Cr√©ation du GraphFrame\n",
    "print(\"\\nüî® Creating GraphFrame...\")\n",
    "g = GraphFrame(vertices, edges)\n",
    "print(\"‚úÖ GraphFrame cr√©√© avec succ√®s!\")\n",
    "\n",
    "# 3. Analyse des degr√©s\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Analyse des Degr√©s (Degree Centrality) ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    print(\"\\nüìä Top 5 des N≈ìuds (V1) les plus connect√©s (Degr√©):\")\n",
    "    degrees_df = g.degrees.orderBy(col(\"degree\").desc())\n",
    "    degrees_df.show(5)\n",
    "    \n",
    "    # Statistiques sur les degr√©s\n",
    "    print(\"\\nüìà Statistiques des degr√©s:\")\n",
    "    g.degrees.describe(\"degree\").show()\n",
    "    \n",
    "    # Distribution des degr√©s\n",
    "    print(\"\\nüìä Distribution des degr√©s:\")\n",
    "    g.degrees.groupBy(\"degree\").count() \\\n",
    "        .orderBy(desc(\"count\")) \\\n",
    "        .show(10)\n",
    "    \n",
    "    # Identifier les n≈ìuds isol√©s\n",
    "    isolated_nodes = g.degrees.filter(col(\"degree\") == 1).count()\n",
    "    print(f\"\\nüîç N≈ìuds isol√©s (degree = 1): {isolated_nodes:,}\")\n",
    "    \n",
    "    # Identifier les hubs (n≈ìuds hautement connect√©s)\n",
    "    high_degree_threshold = 50\n",
    "    hubs = g.degrees.filter(col(\"degree\") > high_degree_threshold)\n",
    "    print(f\"üö® N≈ìuds hautement connect√©s (degree > {high_degree_threshold}): {hubs.count():,}\")\n",
    "    \n",
    "    if hubs.count() > 0:\n",
    "        print(\"\\nExemples de hubs:\")\n",
    "        hubs.orderBy(desc(\"degree\")).show(10)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Avertissement: Le calcul des degr√©s a √©chou√©: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44735382-5115-4516-951c-2888d9f72c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "--- Algorithme des Composantes Connexes (Connected Components) ---\n",
      "======================================================================\n",
      "\n",
      "üîß Configuration du checkpoint directory...\n",
      "‚úÖ R√©pertoire de checkpoint d√©fini: /tmp/gftest_checkpoints\n",
      "\n",
      "üîÑ Calcul des Composantes Connexes en cours...\n",
      "‚è≥ Cela peut prendre quelques minutes...\n",
      "‚úÖ Composantes Connexes calcul√©es!\n",
      "\n",
      "üìä Analyse des composantes...\n",
      "\n",
      "üìà Statistiques G√©n√©rales:\n",
      "   Nombre total de composantes: 275,236\n",
      "\n",
      "üìä Distribution des tailles de composantes:\n",
      "+---------+-------------+\n",
      "|component|componentSize|\n",
      "+---------+-------------+\n",
      "|    20584|           43|\n",
      "|    20650|           27|\n",
      "|    22612|           23|\n",
      "|    19647|           21|\n",
      "|    23632|           18|\n",
      "|    22068|           17|\n",
      "|    15049|           16|\n",
      "|    20867|           15|\n",
      "|    21695|           14|\n",
      "|     5258|           14|\n",
      "+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üìà Statistiques des tailles:\n",
      "+-------+-------------------+\n",
      "|summary|      componentSize|\n",
      "+-------+-------------------+\n",
      "|  count|             275236|\n",
      "|   mean| 1.0015513958929791|\n",
      "| stddev|0.15471630726833405|\n",
      "|    min|                  1|\n",
      "|    max|                 43|\n",
      "+-------+-------------------+\n",
      "\n",
      "\n",
      "======================================================================\n",
      "--- Analyse de la Plus Grande Composante ---\n",
      "======================================================================\n",
      "\n",
      "üéØ Plus Grande Composante (ID: 20584):\n",
      "   Taille Totale: 43 n≈ìuds\n",
      "   Fraudes (label=1): 43\n",
      "   Puret√© (% fraudes): 100.00%\n",
      "   Transactions normales: 0\n",
      "\n",
      "======================================================================\n",
      "--- Composantes Suspectes (Taille 5-50) ---\n",
      "======================================================================\n",
      "\n",
      "Nombre de composantes de taille moyenne: 35\n",
      "\n",
      "Top 10 composantes de taille moyenne:\n",
      "+---------+-------------+\n",
      "|component|componentSize|\n",
      "+---------+-------------+\n",
      "|    20584|           43|\n",
      "|    20650|           27|\n",
      "|    22612|           23|\n",
      "|    19647|           21|\n",
      "|    23632|           18|\n",
      "|    22068|           17|\n",
      "|    15049|           16|\n",
      "|    20867|           15|\n",
      "|     5258|           14|\n",
      "|    16696|           14|\n",
      "+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üîç Analyse de puret√© des composantes moyennes:\n",
      "   Component 20584: 43 n≈ìuds, 43 fraudes (100.0%) üö® SUSPECT\n",
      "   Component 20650: 27 n≈ìuds, 27 fraudes (100.0%) üö® SUSPECT\n",
      "   Component 22612: 23 n≈ìuds, 23 fraudes (100.0%) üö® SUSPECT\n",
      "   Component 19647: 21 n≈ìuds, 21 fraudes (100.0%) üö® SUSPECT\n",
      "   Component 23632: 18 n≈ìuds, 18 fraudes (100.0%) üö® SUSPECT\n",
      "\n",
      "üîç Composantes isol√©es (1 n≈ìud): 275,191\n",
      "\n",
      "‚úÖ Analyse des Composantes Connexes termin√©e!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cellule 5/8 : Algorithme des Composantes Connexes (CC)\n",
    "from pyspark.sql.functions import col, desc, count as spark_count\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"--- Algorithme des Composantes Connexes (Connected Components) ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# D√©finir le r√©pertoire de checkpoint (obligatoire pour CC)\n",
    "print(\"\\nüîß Configuration du checkpoint directory...\")\n",
    "try:\n",
    "    spark.sparkContext.setCheckpointDir(\"/tmp/gftest_checkpoints\")\n",
    "    print(\"‚úÖ R√©pertoire de checkpoint d√©fini: /tmp/gftest_checkpoints\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Avertissement: Impossible de d√©finir le checkpoint ({e}).\")\n",
    "    print(\"L'algorithme CC peut √©chouer.\")\n",
    "    \n",
    "# Calcul des Composantes Connexes\n",
    "print(\"\\nüîÑ Calcul des Composantes Connexes en cours...\")\n",
    "print(\"‚è≥ Cela peut prendre quelques minutes...\")\n",
    "\n",
    "try:\n",
    "    cc_results = g.connectedComponents().persist()\n",
    "    print(\"‚úÖ Composantes Connexes calcul√©es!\")\n",
    "    \n",
    "    # Analyse des R√©sultats\n",
    "    print(\"\\nüìä Analyse des composantes...\")\n",
    "    component_sizes = cc_results.groupBy(\"component\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"componentSize\")\n",
    "    \n",
    "    cc_analysis = cc_results.join(component_sizes, \"component\")\n",
    "    \n",
    "    # Statistiques g√©n√©rales\n",
    "    total_components = component_sizes.count()\n",
    "    print(f\"\\nüìà Statistiques G√©n√©rales:\")\n",
    "    print(f\"   Nombre total de composantes: {total_components:,}\")\n",
    "    \n",
    "    # Distribution des tailles de composantes\n",
    "    print(\"\\nüìä Distribution des tailles de composantes:\")\n",
    "    component_sizes.orderBy(desc(\"componentSize\")).show(10)\n",
    "    \n",
    "    print(\"\\nüìà Statistiques des tailles:\")\n",
    "    component_sizes.describe(\"componentSize\").show()\n",
    "    \n",
    "    # Afficher les statistiques du plus grand groupe\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"--- Analyse de la Plus Grande Composante ---\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    top_component = cc_analysis.orderBy(col(\"componentSize\").desc()).limit(1).collect()[0]\n",
    "    top_component_id = top_component[\"component\"]\n",
    "    total_size = top_component[\"componentSize\"]\n",
    "    \n",
    "    # Compter les fraudes dans la plus grande composante\n",
    "    fraud_in_top = cc_analysis.filter(col('component') == top_component_id) \\\n",
    "        .filter(col('label') == 1).count()\n",
    "    fraud_purity = (fraud_in_top / total_size * 100) if total_size > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüéØ Plus Grande Composante (ID: {top_component_id}):\")\n",
    "    print(f\"   Taille Totale: {total_size:,} n≈ìuds\")\n",
    "    print(f\"   Fraudes (label=1): {fraud_in_top:,}\")\n",
    "    print(f\"   Puret√© (% fraudes): {fraud_purity:.2f}%\")\n",
    "    print(f\"   Transactions normales: {total_size - fraud_in_top:,}\")\n",
    "    \n",
    "    # Analyser les composantes de taille moyenne (potentiels r√©seaux de fraude)\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"--- Composantes Suspectes (Taille 5-50) ---\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    medium_components = component_sizes.filter(\n",
    "        (col(\"componentSize\") >= 5) & (col(\"componentSize\") <= 50)\n",
    "    ).orderBy(desc(\"componentSize\"))\n",
    "    \n",
    "    print(f\"\\nNombre de composantes de taille moyenne: {medium_components.count():,}\")\n",
    "    \n",
    "    if medium_components.count() > 0:\n",
    "        print(\"\\nTop 10 composantes de taille moyenne:\")\n",
    "        medium_components.show(10)\n",
    "        \n",
    "        # Analyser la puret√© de ces composantes\n",
    "        print(\"\\nüîç Analyse de puret√© des composantes moyennes:\")\n",
    "        for row in medium_components.limit(5).collect():\n",
    "            comp_id = row[\"component\"]\n",
    "            comp_size = row[\"componentSize\"]\n",
    "            fraud_count = cc_analysis.filter(col('component') == comp_id) \\\n",
    "                .filter(col('label') == 1).count()\n",
    "            purity = (fraud_count / comp_size * 100) if comp_size > 0 else 0\n",
    "            \n",
    "            status = \"üö® SUSPECT\" if purity > 70 else \"‚úÖ Normal\"\n",
    "            print(f\"   Component {comp_id}: {comp_size} n≈ìuds, {fraud_count} fraudes ({purity:.1f}%) {status}\")\n",
    "    \n",
    "    # Composantes isol√©es (taille = 1)\n",
    "    isolated = component_sizes.filter(col(\"componentSize\") == 1).count()\n",
    "    print(f\"\\nüîç Composantes isol√©es (1 n≈ìud): {isolated:,}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Analyse des Composantes Connexes termin√©e!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erreur lors du calcul des CC: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e8d928-091b-48d1-a6d2-6a5b4a394ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "--- Initialisation des Poids PageRank (Normalisation des Ar√™tes) ---\n",
      "======================================================================\n",
      "\n",
      "üîÑ Step 1: Joining edges with transaction amounts...\n",
      "‚úÖ Edges with amounts: 7,016\n",
      "\n",
      "üîÑ Step 2: Calculating total outgoing amounts per source...\n",
      "‚úÖ Sum weights calculated for 472 sources\n",
      "\n",
      "üîÑ Step 3: Normalizing edge weights...\n",
      "‚úÖ Normalized edges created: 7,016\n",
      "\n",
      "üìä Sample of normalized edges:\n",
      "+------------------+------------------+------------------+\n",
      "|               src|               dst|            weight|\n",
      "+------------------+------------------+------------------+\n",
      "|-0.114360703589856| -1.46489654758402|               0.5|\n",
      "|-0.114360703589856| -0.88525408859895|               0.5|\n",
      "|-0.443793956538852|-0.264868683737295|0.0769230769230769|\n",
      "|-0.443793956538852|  -2.7560071191969|0.0769230769230769|\n",
      "|-0.443793956538852| -1.32278906321956|0.0769230769230769|\n",
      "+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üìà Weight statistics:\n",
      "+-------+--------------------+\n",
      "|summary|              weight|\n",
      "+-------+--------------------+\n",
      "|  count|                6707|\n",
      "|   mean| 0.06664678693901993|\n",
      "| stddev| 0.05739193544133077|\n",
      "|    min|0.023809523809523784|\n",
      "|    max|                 1.0|\n",
      "+-------+--------------------+\n",
      "\n",
      "\n",
      "üîÑ Step 4: Initializing PageRank values...\n",
      "\n",
      "‚úÖ Initialization complete!\n",
      "   Total vertices: 275,663\n",
      "   Total normalized edges: 7,016\n",
      "   Initial PageRank (1/N): 0.00000363\n",
      "\n",
      "üìä Sample of initialized vertices:\n",
      "+----------------+--------------------+-----+\n",
      "|              id|            pagerank|label|\n",
      "+----------------+--------------------+-----+\n",
      "|-1.2768303373631|3.627617779680262E-6|    0|\n",
      "|1.21205680491093|3.627617779680262E-6|    0|\n",
      "|1.08102680841932|3.627617779680262E-6|    0|\n",
      "|1.49157444507907|3.627617779680262E-6|    0|\n",
      "|1.09337038677875|3.627617779680262E-6|    0|\n",
      "+----------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cellule 6/8 : Pr√©paration des Poids PageRank (Normalisation)\n",
    "from pyspark.sql.functions import col, sum as spark_sum, lit, desc\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"--- Initialisation des Poids PageRank (Normalisation des Ar√™tes) ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Joindre 'edges' avec 'df' pour r√©cup√©rer 'Amount'\n",
    "print(\"\\nüîÑ Step 1: Joining edges with transaction amounts...\")\n",
    "edges_with_amount = edges.alias(\"e\").join(\n",
    "    df.select(col(\"V1\").cast(\"string\").alias(\"src_v1\"), col(\"Amount\")).distinct(), \n",
    "    col(\"e.src\") == col(\"src_v1\"),\n",
    "    \"left\"\n",
    ").select(col(\"e.src\"), col(\"e.dst\"), col(\"Amount\")).distinct()\n",
    "\n",
    "print(f\"‚úÖ Edges with amounts: {edges_with_amount.count():,}\")\n",
    "\n",
    "# 2. Calculer la somme totale des montants sortants par source\n",
    "print(\"\\nüîÑ Step 2: Calculating total outgoing amounts per source...\")\n",
    "sum_weights = edges_with_amount.groupBy(\"src\") \\\n",
    "    .agg(spark_sum(\"Amount\").alias(\"total_outgoing_amount\"))\n",
    "\n",
    "print(f\"‚úÖ Sum weights calculated for {sum_weights.count():,} sources\")\n",
    "\n",
    "# 3. Normalisation (Weight = Amount / Total Outgoing)\n",
    "print(\"\\nüîÑ Step 3: Normalizing edge weights...\")\n",
    "edges_with_sum = edges_with_amount.join(sum_weights, \"src\")\n",
    "normalized_edges = edges_with_sum.withColumn(\n",
    "    \"weight\", col(\"Amount\") / col(\"total_outgoing_amount\")\n",
    ").select(col(\"src\"), col(\"dst\"), col(\"weight\"))\n",
    "\n",
    "print(f\"‚úÖ Normalized edges created: {normalized_edges.count():,}\")\n",
    "\n",
    "# V√©rifier la normalisation\n",
    "print(\"\\nüìä Sample of normalized edges:\")\n",
    "normalized_edges.show(5)\n",
    "\n",
    "print(\"\\nüìà Weight statistics:\")\n",
    "normalized_edges.describe(\"weight\").show()\n",
    "\n",
    "# 4. Finaliser l'initialisation du PageRank (1/N)\n",
    "print(\"\\nüîÑ Step 4: Initializing PageRank values...\")\n",
    "N_vertices = vertices.count()\n",
    "\n",
    "# Utiliser le DataFrame 'vertices' ajust√© des √©tapes pr√©c√©dentes\n",
    "vertices = vertices.withColumn(\"pagerank\", lit(1.0 / N_vertices)).cache()\n",
    "\n",
    "print(f\"\\n‚úÖ Initialization complete!\")\n",
    "print(f\"   Total vertices: {N_vertices:,}\")\n",
    "print(f\"   Total normalized edges: {normalized_edges.count():,}\")\n",
    "print(f\"   Initial PageRank (1/N): {1.0 / N_vertices:.8f}\")\n",
    "\n",
    "# V√©rifier l'initialisation\n",
    "print(\"\\nüìä Sample of initialized vertices:\")\n",
    "vertices.select(\"id\", \"pagerank\", \"label\").show(5)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac3e7869-740b-4abc-8944-feb0d422479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "--- PageRank Simul√© (5 it√©rations, alpha=0.15) ---\n",
      "======================================================================\n",
      "\n",
      "üìä Configuration:\n",
      "   Vertices: 275,663\n",
      "   Edges: 7,016\n",
      "   Max iterations: 5\n",
      "   Reset probability (Œ±): 0.15\n",
      "   Initial PageRank: 0.00000363\n",
      "\n",
      "üîÑ Starting PageRank iterations...\n",
      "   Iteration 1/5 completed in 0.27s - Avg PR: 0.00000055, Max PR: 0.00000363\n",
      "   Iteration 2/5 completed in 0.26s - Avg PR: 0.00000055, Max PR: 0.00000363\n",
      "   Iteration 3/5 completed in 0.37s - Avg PR: 0.00000055, Max PR: 0.00000363\n",
      "   Iteration 4/5 completed in 0.53s - Avg PR: 0.00000055, Max PR: 0.00000363\n",
      "   Iteration 5/5 completed in 1.10s - Avg PR: 0.00000055, Max PR: 0.00000363\n",
      "\n",
      "‚úÖ PageRank completed in 22.50s (4.50s per iteration)\n",
      "\n",
      "üîÑ Preparing final results...\n",
      "\n",
      "======================================================================\n",
      "--- Analyse des R√©sultats PageRank ---\n",
      "======================================================================\n",
      "\n",
      "üìà Statistiques PageRank:\n",
      "+-------+--------------------+\n",
      "|summary|            pagerank|\n",
      "+-------+--------------------+\n",
      "|  count|              275663|\n",
      "|   mean|5.485894026413845E-7|\n",
      "| stddev| 1.10792783122001E-7|\n",
      "|    min|5.441426669520393E-7|\n",
      "|    max|3.627617779680262E-6|\n",
      "+-------+--------------------+\n",
      "\n",
      "\n",
      "üèÜ Top 10 Nodes par PageRank:\n",
      "+-----------------+--------------------+-----+------+\n",
      "|id               |pagerank            |label|Amount|\n",
      "+-----------------+--------------------+-----+------+\n",
      "|1.08837493830851 |3.627617779680262E-6|1    |3.79  |\n",
      "|0.753356012421118|3.627617779680262E-6|1    |2.0   |\n",
      "|-14.4744374924863|3.627617779680262E-6|1    |1.0   |\n",
      "|0.269614090485094|3.627617779680262E-6|1    |0.68  |\n",
      "|-15.2713618637585|3.627617779680262E-6|1    |1.0   |\n",
      "|1.1939160689293  |3.627617779680262E-6|1    |31.91 |\n",
      "|-2.92194437582996|3.627617779680262E-6|1    |723.21|\n",
      "|-2.33565492855671|3.627617779680262E-6|1    |444.17|\n",
      "|-1.78322883722709|3.627617779680262E-6|1    |1.0   |\n",
      "|-3.5934760029271 |3.627617779680262E-6|1    |101.5 |\n",
      "+-----------------+--------------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üìä PageRank moyen par Label:\n",
      "+-----+------+--------------------+--------------------+--------------------+\n",
      "|label| count|        avg_pagerank|        max_pagerank|        min_pagerank|\n",
      "+-----+------+--------------------+--------------------+--------------------+\n",
      "|    0|275190|5.441426669527528E-7|5.441426669520393E-7|5.441426669520393E-7|\n",
      "|    1|   473|3.135687064697572E-6|3.627617779680262E-6|5.441426669520393E-7|\n",
      "+-----+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "\n",
      "üö® N≈ìuds suspects (High PageRank + Label=1):\n",
      "   Total frauds: 473\n",
      "   Top 10:\n",
      "+-----------------+--------------------+------+-----+\n",
      "|id               |pagerank            |Amount|label|\n",
      "+-----------------+--------------------+------+-----+\n",
      "|1.08837493830851 |3.627617779680262E-6|3.79  |1    |\n",
      "|0.753356012421118|3.627617779680262E-6|2.0   |1    |\n",
      "|-14.4744374924863|3.627617779680262E-6|1.0   |1    |\n",
      "|0.269614090485094|3.627617779680262E-6|0.68  |1    |\n",
      "|-15.2713618637585|3.627617779680262E-6|1.0   |1    |\n",
      "|1.1939160689293  |3.627617779680262E-6|31.91 |1    |\n",
      "|-2.92194437582996|3.627617779680262E-6|723.21|1    |\n",
      "|-2.33565492855671|3.627617779680262E-6|444.17|1    |\n",
      "|-1.78322883722709|3.627617779680262E-6|1.0   |1    |\n",
      "|-3.5934760029271 |3.627617779680262E-6|101.5 |1    |\n",
      "+-----------------+--------------------+------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "‚úÖ PageRank Simulation termin√©e. R√©sultats pr√™ts.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üîπ Cellule 7/8 : Algorithme PageRank (Simulation Native PySpark)\n",
    "from pyspark.sql.functions import sum as spark_sum, lit, col, coalesce, desc\n",
    "import time\n",
    "\n",
    "MAX_ITER = 5\n",
    "RESET_PROBABILITY = 0.15 \n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"--- PageRank Simul√© ({MAX_ITER} it√©rations, alpha={RESET_PROBABILITY}) ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 'vertices' contient id, label, Amount, pagerank initial\n",
    "current_vertices = vertices.select(\"id\", \"label\", \"pagerank\").cache()\n",
    "N = float(current_vertices.count())\n",
    "\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "print(f\"   Vertices: {int(N):,}\")\n",
    "print(f\"   Edges: {normalized_edges.count():,}\")\n",
    "print(f\"   Max iterations: {MAX_ITER}\")\n",
    "print(f\"   Reset probability (Œ±): {RESET_PROBABILITY}\")\n",
    "print(f\"   Initial PageRank: {1.0/N:.8f}\")\n",
    "\n",
    "print(f\"\\nüîÑ Starting PageRank iterations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    iter_start = time.time()\n",
    "    \n",
    "    # 1. Calcul du Score de contribution (pr * weight)\n",
    "    contributions = current_vertices.join(\n",
    "        normalized_edges, current_vertices.id == normalized_edges.src\n",
    "    ).withColumn(\n",
    "        \"contribution\", col(\"pagerank\") * col(\"weight\")\n",
    "    ).select(col(\"dst\").alias(\"id\"), \"contribution\")\n",
    "    \n",
    "    # 2. Agr√©gation des contributions\n",
    "    new_pageranks = contributions.groupBy(\"id\") \\\n",
    "        .agg(spark_sum(\"contribution\").alias(\"sum_contribution\"))\n",
    "    \n",
    "    # 3. Application de la formule PageRank\n",
    "    current_vertices = current_vertices.drop(\"pagerank\") \\\n",
    "                                       .join(new_pageranks, \"id\", \"left_outer\") \\\n",
    "                                       .withColumn(\n",
    "                                           \"sum_contribution_clean\", \n",
    "                                           coalesce(col(\"sum_contribution\"), lit(0))\n",
    "                                       )\n",
    "    \n",
    "    # PR(new) = (1 - alpha) * PR(contribution) + alpha / N\n",
    "    current_vertices = current_vertices.withColumn(\n",
    "        \"pagerank\", \n",
    "        lit(1.0 - RESET_PROBABILITY) * col(\"sum_contribution_clean\") + lit(RESET_PROBABILITY / N)\n",
    "    ).select(\"id\", \"label\", \"pagerank\").cache()\n",
    "    \n",
    "    iter_time = time.time() - iter_start\n",
    "    \n",
    "    # Show progress with statistics\n",
    "    avg_pr = current_vertices.agg({\"pagerank\": \"avg\"}).collect()[0][0]\n",
    "    max_pr = current_vertices.agg({\"pagerank\": \"max\"}).collect()[0][0]\n",
    "    \n",
    "    print(f\"   Iteration {i+1}/{MAX_ITER} completed in {iter_time:.2f}s - Avg PR: {avg_pr:.8f}, Max PR: {max_pr:.8f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ PageRank completed in {total_time:.2f}s ({total_time/MAX_ITER:.2f}s per iteration)\")\n",
    "\n",
    "# R√©int√©grer la colonne Amount pour l'affichage final\n",
    "print(\"\\nüîÑ Preparing final results...\")\n",
    "results = current_vertices.join(\n",
    "    vertices.select(\n",
    "        \"id\", \n",
    "        \"Amount\", \n",
    "        col(\"label\").alias(\"original_label\")\n",
    "    ), \n",
    "    \"id\", \n",
    "    \"left\"\n",
    ").drop(\"label\").withColumnRenamed(\"original_label\", \"label\")\n",
    "\n",
    "results = results.orderBy(col(\"pagerank\").desc()).cache()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Analyse des R√©sultats PageRank ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Statistiques PageRank\n",
    "print(\"\\nüìà Statistiques PageRank:\")\n",
    "results.describe(\"pagerank\").show()\n",
    "\n",
    "# Top nodes\n",
    "print(\"\\nüèÜ Top 10 Nodes par PageRank:\")\n",
    "results.select(\"id\", \"pagerank\", \"label\", \"Amount\").show(10, truncate=False)\n",
    "\n",
    "# Analyser par label\n",
    "print(\"\\nüìä PageRank moyen par Label:\")\n",
    "from pyspark.sql.functions import avg, max as spark_max, min as spark_min, count as spark_count\n",
    "\n",
    "results.groupBy(\"label\") \\\n",
    "    .agg(\n",
    "        spark_count(\"*\").alias(\"count\"),\n",
    "        avg(\"pagerank\").alias(\"avg_pagerank\"),\n",
    "        spark_max(\"pagerank\").alias(\"max_pagerank\"),\n",
    "        spark_min(\"pagerank\").alias(\"min_pagerank\")\n",
    "    ).orderBy(\"label\").show()\n",
    "\n",
    "# Identifier les n≈ìuds suspects (high PageRank + fraud label)\n",
    "print(\"\\nüö® N≈ìuds suspects (High PageRank + Label=1):\")\n",
    "suspicious = results.filter(col(\"label\") == 1).orderBy(desc(\"pagerank\"))\n",
    "print(f\"   Total frauds: {suspicious.count():,}\")\n",
    "print(\"   Top 10:\")\n",
    "suspicious.show(10, truncate=False)\n",
    "\n",
    "print(\"\\n‚úÖ PageRank Simulation termin√©e. R√©sultats pr√™ts.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bae6cb0-f72a-4560-9af2-dee83527982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "--- R√âSULTATS FINAUX : ANALYSE GRAPHX ---\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "--- Top 10 des Clients/Cartes (V1) avec PageRank le plus √©lev√© ---\n",
      "======================================================================\n",
      "+-----------------+-----+------+--------------------+\n",
      "|id               |label|Amount|PR_Score            |\n",
      "+-----------------+-----+------+--------------------+\n",
      "|1.08837493830851 |1    |3.79  |3.627617779680262E-6|\n",
      "|0.753356012421118|1    |2.0   |3.627617779680262E-6|\n",
      "|-14.4744374924863|1    |1.0   |3.627617779680262E-6|\n",
      "|0.269614090485094|1    |0.68  |3.627617779680262E-6|\n",
      "|-15.2713618637585|1    |1.0   |3.627617779680262E-6|\n",
      "|1.1939160689293  |1    |31.91 |3.627617779680262E-6|\n",
      "|-2.92194437582996|1    |723.21|3.627617779680262E-6|\n",
      "|-2.33565492855671|1    |444.17|3.627617779680262E-6|\n",
      "|-1.78322883722709|1    |1.0   |3.627617779680262E-6|\n",
      "|-3.5934760029271 |1    |101.5 |3.627617779680262E-6|\n",
      "+-----------------+-----+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "======================================================================\n",
      "--- Top 10 Transactions L√©gitimes avec PageRank √©lev√© ---\n",
      "(Mules potentielles)\n",
      "======================================================================\n",
      "+------------------+-----+------+--------------------+\n",
      "|id                |label|Amount|PR_Score            |\n",
      "+------------------+-----+------+--------------------+\n",
      "|1.23443540571793  |0    |1.0   |5.441426669520393E-7|\n",
      "|1.11461216570348  |0    |49.0  |5.441426669520393E-7|\n",
      "|-2.04605635969185 |0    |179.1 |5.441426669520393E-7|\n",
      "|1.12676959578469  |0    |57.0  |5.441426669520393E-7|\n",
      "|-2.36198161446216 |0    |106.25|5.441426669520393E-7|\n",
      "|1.03521119087805  |0    |124.8 |5.441426669520393E-7|\n",
      "|-0.778708617792836|0    |17.85 |5.441426669520393E-7|\n",
      "|-0.695956288436981|0    |3.0   |5.441426669520393E-7|\n",
      "|1.23630429663582  |0    |11.5  |5.441426669520393E-7|\n",
      "|1.17665873351966  |0    |12.5  |5.441426669520393E-7|\n",
      "+------------------+-----+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "======================================================================\n",
      "--- Top 10 Fraudes Confirm√©es (Label=1) ---\n",
      "======================================================================\n",
      "+-----------------+-----+------+--------------------+\n",
      "|id               |label|Amount|PR_Score            |\n",
      "+-----------------+-----+------+--------------------+\n",
      "|1.08837493830851 |1    |3.79  |3.627617779680262E-6|\n",
      "|0.753356012421118|1    |2.0   |3.627617779680262E-6|\n",
      "|-14.4744374924863|1    |1.0   |3.627617779680262E-6|\n",
      "|0.269614090485094|1    |0.68  |3.627617779680262E-6|\n",
      "|-15.2713618637585|1    |1.0   |3.627617779680262E-6|\n",
      "|1.1939160689293  |1    |31.91 |3.627617779680262E-6|\n",
      "|-2.92194437582996|1    |723.21|3.627617779680262E-6|\n",
      "|-2.33565492855671|1    |444.17|3.627617779680262E-6|\n",
      "|-1.78322883722709|1    |1.0   |3.627617779680262E-6|\n",
      "|-3.5934760029271 |1    |101.5 |3.627617779680262E-6|\n",
      "+-----------------+-----+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "======================================================================\n",
      "--- Distribution PageRank par Label ---\n",
      "======================================================================\n",
      "\n",
      "üìä Statistiques par Label:\n",
      "+-----+------+--------------------+--------------------+--------------------+\n",
      "|label| count|              avg_PR|              max_PR|              min_PR|\n",
      "+-----+------+--------------------+--------------------+--------------------+\n",
      "|    0|275190|5.441426669527528E-7|5.441426669520393E-7|5.441426669520393E-7|\n",
      "|    1|   473|3.135687064697572E-6|3.627617779680262E-6|5.441426669520393E-7|\n",
      "+-----+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "\n",
      "======================================================================\n",
      "--- INTERPR√âTATION FINALE ---\n",
      "======================================================================\n",
      "\n",
      "üìä R√©sum√©:\n",
      "   CC: 275236 groupes de fraude d√©tect√©s\n",
      "   N≈ìuds: 275,663 (473 fraudes)\n",
      "   PageRank: Scores de risque calcul√©s pour priorisation\n",
      "\n",
      "‚úÖ La combinaison CC + PageRank fournit une vision compl√®te!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cellule 8/8 : Affichage et Interpr√©tation des R√©sultats Finaux\n",
    "from pyspark.sql.functions import (\n",
    "    col, desc, count as spark_count, avg, \n",
    "    max as spark_max, min as spark_min\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"--- R√âSULTATS FINAUX : ANALYSE GRAPHX ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Renommage de la colonne pour la clart√©\n",
    "final_results = results.withColumnRenamed(\"pagerank\", \"PR_Score\")\n",
    "\n",
    "# 1. Top 10 des Hubs Potentiels\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Top 10 des Clients/Cartes (V1) avec PageRank le plus √©lev√© ---\")\n",
    "print(\"=\" * 70)\n",
    "final_results.select(\"id\", \"label\", \"Amount\", \"PR_Score\").show(10, truncate=False)\n",
    "\n",
    "# 2. Cas potentiels de Mules\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Top 10 Transactions L√©gitimes avec PageRank √©lev√© ---\")\n",
    "print(\"(Mules potentielles)\")\n",
    "print(\"=\" * 70)\n",
    "mules = final_results.filter(col(\"label\") == 0) \\\n",
    "    .orderBy(col(\"PR_Score\").desc())\n",
    "mules.select(\"id\", \"label\", \"Amount\", \"PR_Score\").show(10, truncate=False)\n",
    "\n",
    "# 3. Fraudes confirm√©es\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Top 10 Fraudes Confirm√©es (Label=1) ---\")\n",
    "print(\"=\" * 70)\n",
    "confirmed_frauds = final_results.filter(col(\"label\") == 1) \\\n",
    "    .orderBy(col(\"PR_Score\").desc())\n",
    "confirmed_frauds.select(\"id\", \"label\", \"Amount\", \"PR_Score\").show(10, truncate=False)\n",
    "\n",
    "# 4. Distribution par Label - CORRECTED\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Distribution PageRank par Label ---\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìä Statistiques par Label:\")\n",
    "\n",
    "final_results.groupBy(\"label\").agg(\n",
    "    spark_count(\"*\").alias(\"count\"),\n",
    "    avg(\"PR_Score\").alias(\"avg_PR\"),\n",
    "    spark_max(\"PR_Score\").alias(\"max_PR\"),\n",
    "    spark_min(\"PR_Score\").alias(\"min_PR\")\n",
    ").orderBy(\"label\").show()\n",
    "\n",
    "# 5. Conclusion\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- INTERPR√âTATION FINALE ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_components = cc_analysis.select('component').distinct().count()\n",
    "total_nodes = final_results.count()\n",
    "total_frauds = final_results.filter(col(\"label\") == 1).count()\n",
    "\n",
    "print(f\"\\nüìä R√©sum√©:\")\n",
    "print(f\"   CC: {total_components} groupes de fraude d√©tect√©s\")\n",
    "print(f\"   N≈ìuds: {total_nodes:,} ({total_frauds:,} fraudes)\")\n",
    "print(f\"   PageRank: Scores de risque calcul√©s pour priorisation\")\n",
    "print(f\"\\n‚úÖ La combinaison CC + PageRank fournit une vision compl√®te!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0023f2b-f4a5-4fcd-8d18-544dbf852838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "--- SAVING RESULTS ---\n",
      "======================================================================\n",
      "\n",
      "üíæ Saving PageRank results...\n",
      "‚úÖ Saved: hdfs://namenode:8020/data/graphx/pagerank_1768252535\n",
      "\n",
      "üíæ Saving top 100 results as CSV...\n",
      "‚úÖ Saved: hdfs://namenode:8020/data/graphx/top_nodes_1768252535\n",
      "\n",
      "======================================================================\n",
      "--- VERIFYING SAVED RESULTS IN HDFS ---\n",
      "======================================================================\n",
      "\n",
      "üì• Loading PageRank results from HDFS...\n",
      "‚úÖ Loaded 275,663 rows\n",
      "\n",
      "üèÜ Top 10 nodes from saved results:\n",
      "+-----------------+--------------------+------+-----+\n",
      "|id               |PR_Score            |Amount|label|\n",
      "+-----------------+--------------------+------+-----+\n",
      "|1.08837493830851 |3.627617779680262E-6|3.79  |1    |\n",
      "|0.753356012421118|3.627617779680262E-6|2.0   |1    |\n",
      "|-14.4744374924863|3.627617779680262E-6|1.0   |1    |\n",
      "|0.269614090485094|3.627617779680262E-6|0.68  |1    |\n",
      "|-15.2713618637585|3.627617779680262E-6|1.0   |1    |\n",
      "|1.1939160689293  |3.627617779680262E-6|31.91 |1    |\n",
      "|-2.92194437582996|3.627617779680262E-6|723.21|1    |\n",
      "|-2.33565492855671|3.627617779680262E-6|444.17|1    |\n",
      "|-1.78322883722709|3.627617779680262E-6|1.0   |1    |\n",
      "|-3.5934760029271 |3.627617779680262E-6|101.5 |1    |\n",
      "+-----------------+--------------------+------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üìä Statistics by label:\n",
      "+-----+------+--------------------+--------------------+\n",
      "|label| count|              avg_PR|              max_PR|\n",
      "+-----+------+--------------------+--------------------+\n",
      "|    1|   473|3.135687064697572E-6|3.627617779680262E-6|\n",
      "|    0|275190|5.441426669527528E-7|5.441426669520393E-7|\n",
      "+-----+------+--------------------+--------------------+\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéâ GRAPHX ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Your results are saved in HDFS:\n",
      "   ‚Ä¢ PageRank: hdfs://namenode:8020/data/graphx/pagerank_results_1768187013\n",
      "   ‚Ä¢ Vertices: hdfs://namenode:8020/data/graphx/vertices_1768187013\n",
      "   ‚Ä¢ Latest: hdfs://namenode:8020/data/graphx/pagerank_1768252535\n",
      "\n",
      "üí° Load anytime with:\n",
      "   spark.read.parquet('hdfs://namenode:8020/data/graphx/pagerank_results_1768187013')\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE AND VERIFY GRAPHX RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- SAVING RESULTS ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Save PageRank results\n",
    "print(\"\\nüíæ Saving PageRank results...\")\n",
    "try:\n",
    "    pagerank_path = f\"hdfs://namenode:8020/data/graphx/pagerank_{timestamp}\"\n",
    "    final_results.coalesce(5).write.mode(\"overwrite\").parquet(pagerank_path)\n",
    "    print(f\"‚úÖ Saved: {pagerank_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Save failed: {e}\")\n",
    "\n",
    "# Save top results as CSV\n",
    "print(\"\\nüíæ Saving top 100 results as CSV...\")\n",
    "try:\n",
    "    csv_path = f\"hdfs://namenode:8020/data/graphx/top_nodes_{timestamp}\"\n",
    "    final_results.limit(100).coalesce(1) \\\n",
    "        .write.mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(csv_path)\n",
    "    print(f\"‚úÖ Saved: {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Save failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFY SAVED RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- VERIFYING SAVED RESULTS IN HDFS ---\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load PageRank results from the previous successful save\n",
    "print(\"\\nüì• Loading PageRank results from HDFS...\")\n",
    "try:\n",
    "    pagerank_saved = spark.read.parquet(\"hdfs://namenode:8020/data/graphx/pagerank_results_1768187013\")\n",
    "    print(f\"‚úÖ Loaded {pagerank_saved.count():,} rows\")\n",
    "    \n",
    "    print(\"\\nüèÜ Top 10 nodes from saved results:\")\n",
    "    pagerank_saved.orderBy(desc(\"PR_Score\")).show(10, truncate=False)\n",
    "    \n",
    "    print(\"\\nüìä Statistics by label:\")\n",
    "    from pyspark.sql.functions import avg, max as spark_max, min as spark_min, count as spark_count\n",
    "    \n",
    "    pagerank_saved.groupBy(\"label\").agg(\n",
    "        spark_count(\"*\").alias(\"count\"),\n",
    "        avg(\"PR_Score\").alias(\"avg_PR\"),\n",
    "        spark_max(\"PR_Score\").alias(\"max_PR\")\n",
    "    ).show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load previous results: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ GRAPHX ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n‚úÖ Your results are saved in HDFS:\")\n",
    "print(f\"   ‚Ä¢ PageRank: hdfs://namenode:8020/data/graphx/pagerank_results_1768187013\")\n",
    "print(f\"   ‚Ä¢ Vertices: hdfs://namenode:8020/data/graphx/vertices_1768187013\")\n",
    "if 'pagerank_path' in locals():\n",
    "    print(f\"   ‚Ä¢ Latest: {pagerank_path}\")\n",
    "print(\"\\nüí° Load anytime with:\")\n",
    "print(\"   spark.read.parquet('hdfs://namenode:8020/data/graphx/pagerank_results_1768187013')\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5857b8b-7304-4f6a-8503-a70d92312230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
