{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c737d2-3e7a-4f23-b690-e72b39b80dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphframes\n",
      "  Downloading graphframes-0.6-py2.py3-none-any.whl.metadata (934 bytes)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from graphframes) (1.24.4)\n",
      "Collecting nose (from graphframes)\n",
      "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
      "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m374.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nose, graphframes\n",
      "Successfully installed graphframes-0.6 nose-1.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install graphframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565ca80b-37a0-4f76-9996-8a803d499cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chargement des donn√©es originales ---\n",
      "Nombre total de transactions : 284807\n",
      "root\n",
      " |-- Time: double (nullable = true)\n",
      " |-- V1: double (nullable = true)\n",
      " |-- V2: double (nullable = true)\n",
      " |-- V3: double (nullable = true)\n",
      " |-- V4: double (nullable = true)\n",
      " |-- V5: double (nullable = true)\n",
      " |-- V6: double (nullable = true)\n",
      " |-- V7: double (nullable = true)\n",
      " |-- V8: double (nullable = true)\n",
      " |-- V9: double (nullable = true)\n",
      " |-- V10: double (nullable = true)\n",
      " |-- V11: double (nullable = true)\n",
      " |-- V12: double (nullable = true)\n",
      " |-- V13: double (nullable = true)\n",
      " |-- V14: double (nullable = true)\n",
      " |-- V15: double (nullable = true)\n",
      " |-- V16: double (nullable = true)\n",
      " |-- V17: double (nullable = true)\n",
      " |-- V18: double (nullable = true)\n",
      " |-- V19: double (nullable = true)\n",
      " |-- V20: double (nullable = true)\n",
      " |-- V21: double (nullable = true)\n",
      " |-- V22: double (nullable = true)\n",
      " |-- V23: double (nullable = true)\n",
      " |-- V24: double (nullable = true)\n",
      " |-- V25: double (nullable = true)\n",
      " |-- V26: double (nullable = true)\n",
      " |-- V27: double (nullable = true)\n",
      " |-- V28: double (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Initialisation Spark et Chargement\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, sum as spark_sum, coalesce\n",
    "from pyspark.sql.window import Window\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "# Configuration Spark (pour l'environnement HDFS et GraphFrames)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud-GraphX-Analysis-Final\") \\\n",
    "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Chemin de base HDFS\n",
    "hdfs_base_path = \"hdfs://namenode:8020/fraud_data\"\n",
    "\n",
    "# Chargement du jeu de donn√©es original (comme confirm√© pr√©c√©demment)\n",
    "print(\"--- Chargement des donn√©es originales ---\")\n",
    "try:\n",
    "    df = spark.read.csv(\n",
    "        f\"{hdfs_base_path}/creditcard.csv\", \n",
    "        header=True, \n",
    "        inferSchema=True\n",
    "    )\n",
    "    df.cache()\n",
    "    print(f\"Nombre total de transactions : {df.count()}\")\n",
    "    df.printSchema()\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR DE CHARGEMENT : {e}\")\n",
    "    # Ajoutez ici un chemin de secours si le HDFS n'est pas accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb54aba-476e-4bfc-92d4-79af75816567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cr√©ation des Vertices (Clients V1) ---\n",
      "Nombre de n≈ìuds uniques (V1) : 275663\n",
      "+----------------+-----+------+--------+\n",
      "|              id|label|Amount|pagerank|\n",
      "+----------------+-----+------+--------+\n",
      "|-1.2768303373631|    0| 110.4|     1.0|\n",
      "|1.21205680491093|    0|  2.28|     1.0|\n",
      "|1.08102680841932|    0| 17.24|     1.0|\n",
      "|1.49157444507907|    0|   2.0|     1.0|\n",
      "|1.09337038677875|    0|  49.9|     1.0|\n",
      "+----------------+-----+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 2/8 : Cr√©ation des Vertices (N≈ìuds)\n",
    "print(\"--- Cr√©ation des Vertices (Clients V1) ---\")\n",
    "\n",
    "# Les N≈ìuds sont les identifiants V1 uniques\n",
    "vertices_final = df.select(\n",
    "    col(\"V1\").alias(\"id\"),  \n",
    "    col(\"Class\").alias(\"label\"),\n",
    "    col(\"Amount\")\n",
    ").distinct()\n",
    "\n",
    "# La colonne 'label' doit √™tre num√©rique (0 ou 1) pour les calculs.\n",
    "vertices_final = vertices_final.withColumn(\"label\", col(\"label\").cast(\"int\"))\n",
    "\n",
    "# Le PageRank initial (sera r√©initialis√© plus tard)\n",
    "vertices_final = vertices_final.withColumn(\"pagerank\", lit(1.0))\n",
    "vertices_final.cache()\n",
    "\n",
    "print(f\"Nombre de n≈ìuds uniques (V1) : {vertices_final.count()}\")\n",
    "vertices_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db571b76-e2f5-418b-85d1-be577da39d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cr√©ation des Edges (Liens Frauduleux Co-occurrents) ---\n",
      "Nombre total d'ar√™tes (liens de fraude) : 7016\n",
      "+-----------------+-----------------+\n",
      "|              src|              dst|\n",
      "+-----------------+-----------------+\n",
      "|0.314596589729515|-1.58550536691994|\n",
      "|-4.72771265581559|-2.58961719821269|\n",
      "|-16.5986647432584|-25.2663550194138|\n",
      "|-19.8563223334433|  -27.84818067198|\n",
      "|-2.78724793061533|  -27.84818067198|\n",
      "+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 3/8 : Cr√©ation des Edges (Liens Frauduleux Co-occurrents)\n",
    "print(\"--- Cr√©ation des Edges (Liens Frauduleux Co-occurrents) ---\")\n",
    "\n",
    "edges = df.alias(\"t1\").join(\n",
    "    df.alias(\"t2\"),\n",
    "    (\n",
    "        # 1. Les deux sont des fraudes\n",
    "        (col(\"t1.Class\") == 1) & (col(\"t2.Class\") == 1) &\n",
    "        \n",
    "        # 2. Elles se produisent dans la m√™me heure\n",
    "        ((col(\"t1.Time\") / 3600).cast(\"int\") == (col(\"t2.Time\") / 3600).cast(\"int\")) &\n",
    "        \n",
    "        # 3. Ce sont des entit√©s/clients diff√©rents (src != dst)\n",
    "        (col(\"t1.V1\") != col(\"t2.V1\"))\n",
    "    )\n",
    ").select(\n",
    "    col(\"t1.V1\").alias(\"src\"),\n",
    "    col(\"t2.V1\").alias(\"dst\")\n",
    ").distinct()\n",
    "\n",
    "edges.cache()\n",
    "print(f\"Nombre total d'ar√™tes (liens de fraude) : {edges.count()}\")\n",
    "edges.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0005d2-f742-4493-af1d-6edd2feed00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- V√©rification et Ajustement du Sch√©ma pour GraphFrame ---\n",
      "\n",
      "‚úÖ GraphFrame cr√©√© avec succ√®s.\n",
      "\n",
      "Top 5 des N≈ìuds (V1) les plus connect√©s (Degr√©) :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n",
      "/usr/local/spark/python/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|               id|degree|\n",
      "+-----------------+------+\n",
      "|-10.6457996485752|    84|\n",
      "|-5.31417320646342|    84|\n",
      "|-16.5265065691231|    84|\n",
      "|-2.14441147422114|    84|\n",
      "|-3.14025953779538|    84|\n",
      "+-----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 4/8 : Cr√©ation du GraphFrame et Analyse Structurale\n",
    "\n",
    "# 1. Conversion des IDs en String (Obligatoire pour GraphFrames)\n",
    "print(\"--- V√©rification et Ajustement du Sch√©ma pour GraphFrame ---\")\n",
    "vertices = vertices_final.withColumn(\"id\", col(\"id\").cast(\"string\"))\n",
    "edges = edges.withColumn(\"src\", col(\"src\").cast(\"string\"))\\\n",
    "             .withColumn(\"dst\", col(\"dst\").cast(\"string\"))\n",
    "\n",
    "# 2. Cr√©ation du GraphFrame\n",
    "g = GraphFrame(vertices, edges)\n",
    "print(\"\\n‚úÖ GraphFrame cr√©√© avec succ√®s.\")\n",
    "\n",
    "# 3. Afficher les 5 n≈ìuds les plus connect√©s (Degr√©)\n",
    "try:\n",
    "    print(\"\\nTop 5 des N≈ìuds (V1) les plus connect√©s (Degr√©) :\")\n",
    "    g.degrees.orderBy(col(\"degree\").desc()).show(5)\n",
    "except Exception as e:\n",
    "    print(f\"Avertissement: Le calcul des degr√©s a √©chou√© ({e}). Le GraphFrame n'est peut-√™tre pas enti√®rement fonctionnel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44735382-5115-4516-951c-2888d9f72c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire de checkpoint d√©fini.\n",
      "\n",
      "--- Calcul des Composantes Connexes ---\n",
      "\n",
      "Statistiques pour la Plus Grande Composante (ID: 20584):\n",
      "- Taille Totale : 43\n",
      "- Composition (Label 1) : 43 (Puret√© : 100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Cellule 5/8 : Algorithme des Composantes Connexes (CC)\n",
    "\n",
    "# D√©finir le r√©pertoire de checkpoint (obligatoire pour CC)\n",
    "try:\n",
    "    spark.sparkContext.setCheckpointDir(\"/tmp/gftest_checkpoints\")\n",
    "    print(\"R√©pertoire de checkpoint d√©fini.\")\n",
    "except Exception as e:\n",
    "    print(f\"Avertissement: Impossible de d√©finir le checkpoint ({e}). L'algorithme CC peut √©chouer.\")\n",
    "    \n",
    "print(\"\\n--- Calcul des Composantes Connexes ---\")\n",
    "\n",
    "cc_results = g.connectedComponents().persist()\n",
    "\n",
    "# Analyse des R√©sultats\n",
    "component_sizes = cc_results.groupBy(\"component\").count().withColumnRenamed(\"count\", \"componentSize\")\n",
    "cc_analysis = cc_results.join(component_sizes, \"component\")\n",
    "\n",
    "# Afficher les statistiques du plus grand groupe\n",
    "top_component = cc_analysis.orderBy(col(\"componentSize\").desc()).limit(1).collect()[0]\n",
    "top_component_id = top_component[\"component\"]\n",
    "total_size = top_component[\"componentSize\"]\n",
    "\n",
    "print(f\"\\nStatistiques pour la Plus Grande Composante (ID: {top_component_id}):\")\n",
    "print(f\"- Taille Totale : {total_size}\")\n",
    "print(f\"- Composition (Label 1) : {cc_analysis.filter(col('component') == top_component_id).filter(col('label') == 1).count()} (Puret√© : {cc_analysis.filter(col('component') == top_component_id).filter(col('label') == 1).count() / total_size * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e8d928-091b-48d1-a6d2-6a5b4a394ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initialisation des Poids PageRank (Normalisation des Ar√™tes) ---\n",
      "Le DataFrame 'normalized_edges' est pr√™t avec 7016 ar√™tes.\n",
      "PageRank initial (1/N) : 0.00000363\n"
     ]
    }
   ],
   "source": [
    "# Cellule 6/8 : Pr√©paration des Poids PageRank (Normalisation)\n",
    "\n",
    "print(\"--- Initialisation des Poids PageRank (Normalisation des Ar√™tes) ---\")\n",
    "\n",
    "# 1. Joindre 'edges' avec 'df' pour r√©cup√©rer 'Amount'\n",
    "edges_with_amount = edges.alias(\"e\").join(\n",
    "    df.select(col(\"V1\").cast(\"string\").alias(\"src_v1\"), col(\"Amount\")).distinct(), \n",
    "    col(\"e.src\") == col(\"src_v1\"),\n",
    "    \"left\"\n",
    ").select(col(\"e.src\"), col(\"e.dst\"), col(\"Amount\")).distinct()\n",
    "\n",
    "# 2. Calculer la somme totale des montants sortants par source\n",
    "sum_weights = edges_with_amount.groupBy(\"src\").agg(spark_sum(\"Amount\").alias(\"total_outgoing_amount\"))\n",
    "\n",
    "# 3. Normalisation (Weight = Amount / Total Outgoing)\n",
    "edges_with_sum = edges_with_amount.join(sum_weights, \"src\")\n",
    "normalized_edges = edges_with_sum.withColumn(\n",
    "    \"weight\", col(\"Amount\") / col(\"total_outgoing_amount\")\n",
    ").select(col(\"src\"), col(\"dst\"), col(\"weight\"))\n",
    "\n",
    "# 4. Finaliser l'initialisation du PageRank (1/N)\n",
    "N_vertices = vertices.count()\n",
    "# Utiliser le DataFrame 'vertices' ajust√© des √©tapes pr√©c√©dentes\n",
    "vertices = vertices.withColumn(\"pagerank\", lit(1.0 / N_vertices)).cache()\n",
    "\n",
    "print(f\"Le DataFrame 'normalized_edges' est pr√™t avec {normalized_edges.count()} ar√™tes.\")\n",
    "print(f\"PageRank initial (1/N) : {1.0 / N_vertices:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3e7869-740b-4abc-8944-feb0d422479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PageRank Simul√© (5 it√©rations) ---\n",
      "It√©ration 1 compl√©t√©e.\n",
      "It√©ration 2 compl√©t√©e.\n",
      "It√©ration 3 compl√©t√©e.\n",
      "It√©ration 4 compl√©t√©e.\n",
      "It√©ration 5 compl√©t√©e.\n",
      "\n",
      "PageRank Simulation termin√©e. R√©sultats pr√™ts pour l'affichage.\n"
     ]
    }
   ],
   "source": [
    "# üîπ Cellule 7/8 : Algorithme PageRank (Simulation Native PySpark)\n",
    "\n",
    "from pyspark.sql.functions import sum, lit, col, coalesce # S'assurer que les fonctions sont bien import√©es\n",
    "\n",
    "MAX_ITER = 5\n",
    "RESET_PROBABILITY = 0.15 \n",
    "\n",
    "print(f\"\\n--- PageRank Simul√© ({MAX_ITER} it√©rations) ---\")\n",
    "\n",
    "# 'vertices' contient id, label, Amount, pagerank initial. On commence avec id, label, pagerank\n",
    "current_vertices = vertices.select(\"id\", \"label\", \"pagerank\").cache()\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    # 1. Calcul du Score de contribution (pr * weight)\n",
    "    contributions = current_vertices.join(\n",
    "        normalized_edges, current_vertices.id == normalized_edges.src\n",
    "    ).withColumn(\n",
    "        \"contribution\", col(\"pagerank\") * col(\"weight\")\n",
    "    ).select(col(\"dst\").alias(\"id\"), \"contribution\")\n",
    "    \n",
    "    # 2. Agr√©gation des contributions\n",
    "    new_pageranks = contributions.groupBy(\"id\").agg(sum(\"contribution\").alias(\"sum_contribution\"))\n",
    "    \n",
    "    # 3. Application de la formule PageRank\n",
    "    current_vertices = current_vertices.drop(\"pagerank\")\\\n",
    "                                       .join(new_pageranks, \"id\", \"left_outer\")\\\n",
    "                                       .withColumn(\n",
    "                                           \"sum_contribution_clean\", \n",
    "                                           coalesce(col(\"sum_contribution\"), lit(0))\n",
    "                                       )\n",
    "    \n",
    "    N = float(current_vertices.count())\n",
    "    \n",
    "    # PR(new) = (1 - alpha) * PR(contribution) + alpha / N\n",
    "    current_vertices = current_vertices.withColumn(\n",
    "        \"pagerank\", \n",
    "        lit(1.0 - RESET_PROBABILITY) * col(\"sum_contribution_clean\") + lit(RESET_PROBABILITY / N)\n",
    "    ).select(\"id\", \"label\", \"pagerank\").cache()\n",
    "    \n",
    "    print(f\"It√©ration {i+1} compl√©t√©e.\")\n",
    "    \n",
    "# R√©int√©grer la colonne Amount pour l'affichage final, en s√©lectionnant et renommant les colonnes clairement\n",
    "# *********************************** CORRECTION ICI *********************************\n",
    "results = current_vertices.join(\n",
    "    vertices.select(\n",
    "        \"id\", \n",
    "        \"Amount\", \n",
    "        col(\"label\").alias(\"original_label\") # Renommer pour √©viter l'ambigu√Øt√©\n",
    "    ), \n",
    "    \"id\", \n",
    "    \"left\"\n",
    ").drop(\"label\").withColumnRenamed(\"original_label\", \"label\") # Supprimer le label ambigu et renommer le bon\n",
    "\n",
    "results = results.orderBy(col(\"pagerank\").desc())\n",
    "print(\"\\nPageRank Simulation termin√©e. R√©sultats pr√™ts pour l'affichage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bae6cb0-f72a-4560-9af2-dee83527982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 des Clients/Cartes (V1) ayant le PageRank le plus √©lev√© (Hubs potentiels) ---\n",
      "+-----------------+-----+------+--------------------+\n",
      "|id               |label|Amount|PR_Score            |\n",
      "+-----------------+-----+------+--------------------+\n",
      "|-7.50392623748137|1    |12.31 |3.627617779680262E-6|\n",
      "|-2.4340041522657 |1    |362.55|3.627617779680262E-6|\n",
      "|-2.98646550822273|1    |1.79  |3.627617779680262E-6|\n",
      "|-17.5375916846763|1    |9.82  |3.627617779680262E-6|\n",
      "|1.22761441351286 |1    |98.01 |3.627617779680262E-6|\n",
      "|1.37855899734127 |1    |0.76  |3.627617779680262E-6|\n",
      "|0.432554461820961|1    |1.0   |3.627617779680262E-6|\n",
      "|-2.78386548658584|1    |156.0 |3.627617779680262E-6|\n",
      "|0.467991939825149|1    |120.54|3.627617779680262E-6|\n",
      "|1.24384844934819 |1    |1.0   |3.627617779680262E-6|\n",
      "+-----------------+-----+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "--- Top 5 des Transactions L√©gitimes (Label 0) avec PageRank √©lev√© (Mules potentielles) ---\n",
      "+------------------+--------------------+------+-----+\n",
      "|id                |PR_Score            |Amount|label|\n",
      "+------------------+--------------------+------+-----+\n",
      "|-4.06686227118254 |5.441426669520393E-7|355.51|0    |\n",
      "|-0.436905071360625|5.441426669520393E-7|0.89  |0    |\n",
      "|0.951278275520493 |5.441426669520393E-7|58.0  |0    |\n",
      "|-1.49466784074271 |5.441426669520393E-7|28.28 |0    |\n",
      "|-1.2768303373631  |5.441426669520393E-7|110.4 |0    |\n",
      "+------------------+--------------------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "--- Interpr√©tation Finale ---\n",
      "CC : 22 groupes de fraude d√©tect√©s.\n",
      "PageRank : Les scores PageRank permettent de classer le risque au sein du groupe principal.\n",
      "La combinaison CC + PageRank fournit une vision compl√®te de l'organisation de la fraude.\n"
     ]
    }
   ],
   "source": [
    "# Cellule 8/8 : Affichage et Interpr√©tation des R√©sultats Finaux\n",
    "\n",
    "# Renommage de la colonne pour la clart√©\n",
    "final_results = results.withColumnRenamed(\"pagerank\", \"PR_Score\")\n",
    "\n",
    "# 1. Top 10 des Hubs Potentiels\n",
    "print(\"\\n--- Top 10 des Clients/Cartes (V1) ayant le PageRank le plus √©lev√© (Hubs potentiels) ---\")\n",
    "final_results.select(\"id\", \"label\", \"Amount\", \"PR_Score\").show(10, truncate=False)\n",
    "\n",
    "# 2. Cas potentiels de Mules (transactions l√©gitimes avec un PageRank √©lev√©)\n",
    "print(\"\\n--- Top 5 des Transactions L√©gitimes (Label 0) avec PageRank √©lev√© (Mules potentielles) ---\")\n",
    "final_results.filter(col(\"label\") == 0) \\\n",
    "    .orderBy(col(\"PR_Score\").desc()) \\\n",
    "    .show(5, truncate=False)\n",
    "\n",
    "# 3. Conclusion des r√©sultats\n",
    "print(\"\\n--- Interpr√©tation Finale ---\")\n",
    "print(f\"CC : {cc_analysis.select('componentSize').distinct().count()} groupes de fraude d√©tect√©s.\")\n",
    "print(\"PageRank : Les scores PageRank permettent de classer le risque au sein du groupe principal.\")\n",
    "print(\"La combinaison CC + PageRank fournit une vision compl√®te de l'organisation de la fraude.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0023f2b-f4a5-4fcd-8d18-544dbf852838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65e303-0712-4f7c-992e-ffd5a37e4dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
