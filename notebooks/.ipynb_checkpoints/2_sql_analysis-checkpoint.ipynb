{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - SQL Analysis\n",
    "Analyse des donnÃ©es via Spark SQL Ã©tape par Ã©tape."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Ã‰tape 1 : Initialisation Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud-SQL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Ã‰tape 2 : Charger dataset Parquet\n",
    "train_df = spark.read.parquet(\"hdfs:///user/hadoop/BigDataFraude_ML-GraphX/train\")\n",
    "train_df.createOrReplaceTempView(\"train_transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Ã‰tape 3 : Nombre de transactions par classe\n",
    "df_class_count = spark.sql(\"SELECT Class AS label, COUNT(*) AS count FROM train_transactions GROUP BY Class\")\n",
    "df_class_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Ã‰tape 4 : Montant moyen par classe\n",
    "df_avg_amount = spark.sql(\"SELECT Class AS label, AVG(Amount) AS avg_amount FROM train_transactions GROUP BY Class\")\n",
    "df_avg_amount.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
