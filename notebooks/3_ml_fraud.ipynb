{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32864f5",
   "metadata": {},
   "source": [
    "# Notebook 3 - Machine Learning Fraud Detection\n",
    "**Objectif :** Entra√Æner le GBTClassifier, mieux adapt√© aux donn√©es d√©s√©quilibr√©es, et utiliser l'AUC-PR pour une √©valuation pertinente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aac0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/05 01:43:49 WARN Utils: Your hostname, TUF-GAMING-FX504GD, resolves to a loopback address: 127.0.1.1; using 192.168.1.145 instead (on interface wlo1)\n",
      "26/01/05 01:43:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/05 01:43:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 1 : Initialisation Spark et Imports\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier # Changement : GBTClassifier au lieu de LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud-ML\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900c9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chargement et Split du CSV original ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 2 : Charger le dataset et effectuer le split train/test (CORRECTION)\n",
    "print(\"--- Chargement et Split du CSV original ---\")\n",
    "# Rechargez le CSV pour √™tre s√ªr d'avoir toutes les colonnes (V1, V2, ..., Amount, Class, Time)\n",
    "full_df = spark.read.csv(\"hdfs:///user/hadoop/BigDataFraude_ML-GraphX/creditcard.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Effectuer le split ici (remplace le chargement des fichiers Parquet train/test)\n",
    "# Ratio typique 80/20 ou 70/30. Utilisez un seed pour la reproductibilit√©.\n",
    "train_df, test_df = full_df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebd8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assemblage des features effectu√© avec succ√®s.\n"
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 3 : Pr√©parer les features (Correction pour Robustesse)\n",
    "feature_cols = [c for c in train_df.columns if c not in [\"Class\", \"Time\"]]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# --- AJOUT DE LA CORRECTION ---\n",
    "# Si le DataFrame a d√©j√† une colonne 'features' (suite √† une r√©ex√©cution), supprimez-la.\n",
    "if \"features\" in train_df.columns:\n",
    "    print(\"La colonne 'features' existe d√©j√† dans train_df. Suppression...\")\n",
    "    train_df = train_df.drop(\"features\")\n",
    "if \"features\" in test_df.columns:\n",
    "    print(\"La colonne 'features' existe d√©j√† dans test_df. Suppression...\")\n",
    "    test_df = test_df.drop(\"features\")\n",
    "# ------------------------------\n",
    "\n",
    "train_ml = assembler.transform(train_df).select(\"features\", col(\"Class\").alias(\"label\"))\n",
    "test_ml = assembler.transform(test_df).select(\"features\", col(\"Class\").alias(\"label\"))\n",
    "\n",
    "print(\"Assemblage des features effectu√© avec succ√®s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e589e43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entra√Ænement du GBTClassifier ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/05 01:43:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 4 : Cr√©ation et entra√Ænement du mod√®le GBTClassifier\n",
    "print(\"--- Entra√Ænement du GBTClassifier ---\")\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "gbt_model = gbt.fit(train_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f732ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Aper√ßu des pr√©dictions ---\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |label|prediction|probability                             |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n",
      "|[-1.35835406159823,-1.34016307473609,1.77320934263119,0.379779593034328,-0.503198133318193,1.80049938079263,0.791460956450422,0.247675786588991,-1.51465432260583,0.207642865216696,0.624501459424895,0.066083685268831,0.717292731410831,-0.165945922763554,2.34586494901581,-2.89008319444231,1.10996937869599,-0.121359313195888,-2.26185709530414,0.524979725224404,0.247998153469754,0.771679401917229,0.909412262347719,-0.689280956490685,-0.327641833735251,-0.139096571514147,-0.0553527940384261,-0.0597518405929204,378.66]          |0    |0.0       |[0.934087723961792,0.06591227603820804] |\n",
      "|[1.22965763450793,0.141003507049326,0.0453707735899449,1.20261273673594,0.191880988597645,0.272708122899098,-0.00515900288250983,0.0812129398830894,0.464959994783886,-0.0992543211289237,-1.41690724314928,-0.153825826253651,-0.75106271556262,0.16737196252175,0.0501435942254188,-0.443586797916727,0.00282051247234708,-0.61198733994012,-0.0455750446637976,-0.21963255278686,-0.167716265815783,-0.270709726172363,-0.154103786809305,-0.780055415004671,0.75013693580659,-0.257236845917139,0.0345074297438413,0.00516776890624916,4.99]|0    |0.0       |[0.93410826680292,0.06589173319707997]  |\n",
      "|[-0.644269442348146,1.41796354547385,1.0743803763556,-0.492199018495015,0.948934094764157,0.428118462833089,1.12063135838353,-3.80786423873589,0.615374730667027,1.24937617815176,-0.619467796121913,0.291474353088705,1.75796421396042,-1.32386521970526,0.686132504394383,-0.0761269994382006,-1.2221273453247,-0.358221569869078,0.324504731321494,-0.156741852488285,1.94346533978412,-1.01545470979971,0.057503529867291,-0.649709005559993,-0.415266566234811,-0.0516342969262494,-1.20692108094258,-1.08533918832377,40.8]               |0    |0.0       |[0.9340875473512039,0.06591245264879608]|\n",
      "|[-0.33826175242575,1.11959337641566,1.04436655157316,-0.222187276738296,0.49936080649727,-0.24676110061991,0.651583206489972,0.0695385865186387,-0.736727316364109,-0.366845639206541,1.01761446783262,0.836389570307029,1.00684351373408,-0.443522816876142,0.150219101422635,0.739452777052119,-0.540979921943059,0.47667726004282,0.451772964394125,0.203711454727929,-0.246913936910008,-0.633752642406113,-0.12079408408185,-0.385049925313426,-0.0697330460416923,0.0941988339514961,0.246219304619926,0.0830756493473326,3.68]           |0    |0.0       |[0.9340876020508653,0.06591239794913473]|\n",
      "|[1.0693735878819,0.287722129331455,0.828612726634281,2.71252042961718,-0.178398016248009,0.337543730282968,-0.0967168617395962,0.115981735546597,-0.221082566236194,0.460230444301678,-0.773656930526689,0.32338724546722,-0.0110758870883779,-0.178485175177916,-0.65556427824926,-0.19992517131173,0.1240054151819,-0.980496201537345,-0.982916082135047,-0.153197231044512,-0.0368755317335273,0.0744124028162195,-0.0714074332998586,0.104743752596029,0.548264725394119,0.104094153162781,0.0214910583643189,0.021293311477486,27.5]       |0    |0.0       |[0.9340991777591539,0.06590082224084615]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 5 : Pr√©dictions sur le test set\n",
    "predictions = gbt_model.transform(test_ml)\n",
    "print(\"--- Aper√ßu des pr√©dictions ---\")\n",
    "predictions.select(\"features\", \"label\", \"prediction\", \"probability\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711f4a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- √âvaluation des M√©triques ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:====>                                                  (1 + 11) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.7156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 6 : √âvaluation du mod√®le (AUC-ROC et AUC-PR)\n",
    "print(\"--- √âvaluation des M√©triques ---\")\n",
    "\n",
    "# 1. AUC-ROC\n",
    "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator_roc.evaluate(predictions)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# 2. AUC-PR (Plus pertinent pour l'imbalance)\n",
    "evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "pr_auc = evaluator_pr.evaluate(predictions)\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512a1bf4-783d-4b70-9a73-b8dc023fb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sauvegarde du mod√®le LOCALE dans : file:///tmp/spark_models/fraude_gbt_final_1767574836 ---\n",
      " Sauvegarde r√©ussie (Chemin Garanti Unique).\n",
      "\n",
      " Le chemin FINAL √† utiliser dans spark_streaming.py est : file:///tmp/spark_models/fraude_gbt_final_1767574836\n"
     ]
    }
   ],
   "source": [
    "# Cellule de Sauvegarde\n",
    "from pyspark.ml import Pipeline\n",
    "import time\n",
    "\n",
    "# S'assurer que le PipelineModel est frais\n",
    "pipeline = Pipeline(stages=[assembler, gbt_model])\n",
    "pipeline_model = pipeline.fit(train_df) \n",
    "\n",
    "# Utiliser un timestamp pour garantir un chemin UNIQUE, ce qui permet d'√©viter .overwrite()\n",
    "timestamp = int(time.time())\n",
    "MODEL_SAVE_PATH = f\"file:///tmp/spark_models/fraude_gbt_final_{timestamp}\"\n",
    "\n",
    "print(f\"--- Sauvegarde du mod√®le LOCALE dans : {MODEL_SAVE_PATH} ---\")\n",
    "\n",
    "try:\n",
    "    # Sauvegarde \n",
    "    pipeline_model.save(MODEL_SAVE_PATH)\n",
    "    print(\" Sauvegarde r√©ussie (Chemin Garanti Unique).\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"√âCHEC CRITIQUE : {e}\")\n",
    "    raise e\n",
    "\n",
    "# D√©finir le chemin final pour l'√©tape de streaming\n",
    "FINAL_MODEL_PATH = MODEL_SAVE_PATH\n",
    "print(f\"\\n Le chemin FINAL √† utiliser dans spark_streaming.py est : {FINAL_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abf24e-a7f1-47a5-abff-2eda3c2a000c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
