{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdefb5f",
   "metadata": {},
   "source": [
    "# Notebook 2 - SQL Analysis\n",
    "**Objectif :** Effectuer des agr√©gations exploratoires sur les donn√©es originales (non transform√©es) via Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc87ffb-5507-4776-9c62-250ac9124918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark 3.5.0 session created\n"
     ]
    }
   ],
   "source": [
    "# √âtape 1 : Initialisation Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud-SQL-Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"‚úÖ Spark {spark.version} session created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db792a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sch√©ma du DataFrame d'entra√Ænement Parquet :\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[38648.0,1.572105...|    0|\n",
      "|[38649.0,-0.26639...|    0|\n",
      "|[38649.0,0.649402...|    0|\n",
      "|[38650.0,0.820778...|    0|\n",
      "|[38652.0,1.129032...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# √âtape 2 : Charger le dataset CSV original et cr√©er la vue temporaire \n",
    "# Chemin de base HDFS (h√¥te:port)\n",
    "hdfs_base_path = \"hdfs://namenode:8020/data\"\n",
    "\n",
    "# 1. Charger les donn√©es d'entra√Ænement (Train)\n",
    "# Correction de l'URI HDFS : hdfs://namenode:8020/fraud_data/train\n",
    "train_df = spark.read.parquet(f\"{hdfs_base_path}/train\")\n",
    "\n",
    "# 2. Charger les donn√©es de test (Test)\n",
    "test_df = spark.read.parquet(f\"{hdfs_base_path}/test\")\n",
    "\n",
    "# 3. Cr√©er la vue temporaire pour l'analyse SQL (en utilisant les donn√©es d'entra√Ænement)\n",
    "train_df.createOrReplaceTempView(\"train_transactions\")\n",
    "test_df.createOrReplaceTempView(\"test_transactions\")\n",
    "\n",
    "# V√©rification\n",
    "print(\"Sch√©ma du DataFrame d'entra√Ænement Parquet :\")\n",
    "train_df.printSchema()\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c876168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Nombre de transactions par classe ---\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|   400|\n",
      "|    0|227645|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# √âtape 3 : Nombre de transactions par classe \n",
    "print(\"--- Nombre de transactions par classe ---\")\n",
    "df_class_count = spark.sql(\"SELECT label, COUNT(*) AS count FROM train_transactions GROUP BY label\")\n",
    "df_class_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806b6642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Montant moyen et √âcart-type par classe ---\n",
      "+-----+------------------+------------------+\n",
      "|label|        avg_amount|     stddev_amount|\n",
      "+-----+------------------+------------------+\n",
      "|    1|125.60019999999999|258.35134450196875|\n",
      "|    0|  88.3355424454762| 249.5706177774838|\n",
      "+-----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üîπ √âtape 4 : Montant moyen et √âcart-type par classe \n",
    "from pyspark.ml.functions import vector_to_array # Importation de la fonction vector_to_array\n",
    "from pyspark.sql.functions import col, avg, stddev\n",
    "\n",
    "print(\"\\n--- Montant moyen et √âcart-type par classe ---\")\n",
    "\n",
    "# 1. Conversion du vecteur 'features' en tableau (Array)\n",
    "df_array = train_df.withColumn(\n",
    "    \"features_array\",\n",
    "    vector_to_array(col(\"features\"))\n",
    ")\n",
    "\n",
    "# 2. Extraction de la colonne 'Amount' du tableau\n",
    "df_with_amount = df_array.withColumn(\n",
    "    \"Amount\",\n",
    "    col(\"features_array\").getItem(29)\n",
    ")\n",
    "\n",
    "# 3. Calcul des statistiques\n",
    "df_avg_amount = df_with_amount.groupBy(\"label\").agg(\n",
    "    avg(col(\"Amount\")).alias(\"avg_amount\"),\n",
    "    stddev(col(\"Amount\")).alias(\"stddev_amount\")\n",
    ")\n",
    "\n",
    "# 4. Affichage des r√©sultats\n",
    "df_avg_amount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0c27a5-200f-4728-8339-d2eea88cc828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. INITIALISATION (comme section 1 du TP)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, sum, max, min, stddev, when\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud-GroupBy-OrderBy\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. CHARGEMENT DES DONN√âES (comme section 2.2 du TP)\n",
    "hdfs_base_path = \"hdfs://namenode:8020/data\"\n",
    "\n",
    "# Charger les donn√©es Parquet\n",
    "train_df = spark.read.parquet(f\"{hdfs_base_path}/train\")\n",
    "\n",
    "# 3. EXTRACTION DU MONTANT (si besoin)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# Convertir le vecteur features en tableau\n",
    "df_array = train_df.withColumn(\"features_array\", vector_to_array(col(\"features\")))\n",
    "\n",
    "# Extraire le montant (position 29 selon ton TP)\n",
    "df_with_amount = df_array.withColumn(\"Amount\", col(\"features_array\")[29])\n",
    "\n",
    "# Cr√©er une vue SQL\n",
    "df_with_amount.createOrReplaceTempView(\"transactions\")\n",
    "\n",
    "# 4. MAINTENANT LES GROUP BY ET ORDER BY FONCTIONNERONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7dee7d7-8264-4a81-aa66-ae3dd79f832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Transactions par classe ===\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|   400|\n",
      "|    0|227645|\n",
      "+-----+------+\n",
      "\n",
      "\n",
      "=== Statistiques par classe ===\n",
      "+-----+---------------+------------------+--------------------+----------+----------+------------------+\n",
      "|label|nb_transactions|        avg_amount|        total_amount|max_amount|min_amount|        std_amount|\n",
      "+-----+---------------+------------------+--------------------+----------+----------+------------------+\n",
      "|    1|            400|125.60019999999999|  50240.079999999994|   2125.87|       0.0|258.35134450196875|\n",
      "|    0|         227645|  88.3355424454762|2.0109144560000427E7|  25691.16|       0.0| 249.5706177774838|\n",
      "+-----+---------------+------------------+--------------------+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a) Nombre de transactions par classe\n",
    "df_grouped = train_df.groupBy(\"label\").count()\n",
    "print(\"=== Transactions par classe ===\")\n",
    "df_grouped.show()\n",
    "\n",
    "# b) Avec plusieurs agr√©gations\n",
    "print(\"\\n=== Statistiques par classe ===\")\n",
    "df_with_amount.groupBy(\"label\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"nb_transactions\"),\n",
    "        avg(\"Amount\").alias(\"avg_amount\"),\n",
    "        sum(\"Amount\").alias(\"total_amount\"),\n",
    "        max(\"Amount\").alias(\"max_amount\"),\n",
    "        min(\"Amount\").alias(\"min_amount\"),\n",
    "        stddev(\"Amount\").alias(\"std_amount\")\n",
    "    ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9395347d-8790-430a-801a-e23e91383fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tri ascendant par nombre ===\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|   400|\n",
      "|    0|227645|\n",
      "+-----+------+\n",
      "\n",
      "\n",
      "=== Tri descendant par nombre ===\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    0|227645|\n",
      "|    1|   400|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tri ascendant\n",
    "print(\"\\n=== Tri ascendant par nombre ===\")\n",
    "df_grouped.orderBy(\"count\").show()\n",
    "\n",
    "# Tri descendant\n",
    "print(\"\\n=== Tri descendant par nombre ===\")\n",
    "df_grouped.orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c14bac-11bd-4522-aa79-541de1772ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Version SQL ===\n",
      "+-----+---------------+----------+----------+\n",
      "|label|nb_transactions|avg_amount|max_amount|\n",
      "+-----+---------------+----------+----------+\n",
      "|    0|         227645|     88.34|  25691.16|\n",
      "|    1|            400|     125.6|   2125.87|\n",
      "+-----+---------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Version SQL ===\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        label,\n",
    "        COUNT(*) as nb_transactions,\n",
    "        ROUND(AVG(Amount), 2) as avg_amount,\n",
    "        ROUND(MAX(Amount), 2) as max_amount\n",
    "    FROM transactions\n",
    "    GROUP BY label\n",
    "    ORDER BY nb_transactions DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93294971-505a-481d-9ebb-3d8e78d206e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analyse par plages de montants ===\n",
      "+-----+------------+-----+------------------+\n",
      "|label|amount_range|count|      avg_in_range|\n",
      "+-----+------------+-----+------------------+\n",
      "|    0|        0-10|77750| 3.698326045016149|\n",
      "|    0|       10-50|73973|25.126650669838863|\n",
      "|    0|     100-500|38250|208.45337437908464|\n",
      "|    0|       1000+| 2444|1773.9250327332243|\n",
      "|    0|      50-100|30061|  71.8065796214364|\n",
      "|    0|    500-1000| 5167| 676.5074588736212|\n",
      "|    1|        0-10|  203| 1.731871921182266|\n",
      "|    1|       10-50|   47|26.684468085106385|\n",
      "|    1|     100-500|   79|238.57974683544307|\n",
      "|    1|       1000+|    7|1475.8085714285714|\n",
      "|    1|      50-100|   41| 87.31292682926829|\n",
      "|    1|    500-1000|   23| 690.2630434782608|\n",
      "+-----+------------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Analyse par plages de montants ===\")\n",
    "\n",
    "df_with_bins = df_with_amount.withColumn(\n",
    "    \"amount_range\",\n",
    "    when(col(\"Amount\") < 10, \"0-10\")\n",
    "    .when(col(\"Amount\") < 50, \"10-50\")\n",
    "    .when(col(\"Amount\") < 100, \"50-100\")\n",
    "    .when(col(\"Amount\") < 500, \"100-500\")\n",
    "    .when(col(\"Amount\") < 1000, \"500-1000\")\n",
    "    .otherwise(\"1000+\")\n",
    ")\n",
    "\n",
    "df_with_bins.groupBy(\"label\", \"amount_range\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"count\"),\n",
    "        avg(\"Amount\").alias(\"avg_in_range\")\n",
    "    ) \\\n",
    "    .orderBy(\"label\", \"amount_range\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e1b5f5-e0db-44e7-96a7-68000e306afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+------------------+\n",
      "|label|    nb|               avg|               std|\n",
      "+-----+------+------------------+------------------+\n",
      "|    1|   400|125.60019999999999|258.35134450196875|\n",
      "|    0|227645|  88.3355424454762| 249.5706177774838|\n",
      "+-----+------+------------------+------------------+\n",
      "\n",
      "+-------+\n",
      "| Amount|\n",
      "+-------+\n",
      "|2125.87|\n",
      "|1504.93|\n",
      "|1402.16|\n",
      "|1389.56|\n",
      "|1354.25|\n",
      "| 1335.0|\n",
      "|1218.89|\n",
      "| 996.27|\n",
      "| 925.31|\n",
      "| 829.41|\n",
      "+-------+\n",
      "\n",
      "+-----+------------+------+\n",
      "|label|amount_range| count|\n",
      "+-----+------------+------+\n",
      "|    0|        0-10| 77750|\n",
      "|    0|      10-100|104034|\n",
      "|    0|    100-1000| 43417|\n",
      "|    0|       1000+|  2444|\n",
      "|    1|        0-10|   203|\n",
      "|    1|      10-100|    88|\n",
      "|    1|    100-1000|   102|\n",
      "|    1|       1000+|     7|\n",
      "+-----+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Distribution des montants par classe avec tri\n",
    "df_with_amount.groupBy(\"label\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"nb\"),\n",
    "        avg(\"Amount\").alias(\"avg\"),\n",
    "        stddev(\"Amount\").alias(\"std\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"avg\").desc()) \\\n",
    "    .show()\n",
    "\n",
    "# 2. Top 10 des montants les plus √©lev√©s par classe\n",
    "df_with_amount.filter(col(\"label\") == 1) \\\n",
    "    .select(\"Amount\") \\\n",
    "    .orderBy(col(\"Amount\").desc()) \\\n",
    "    .limit(10) \\\n",
    "    .show()\n",
    "\n",
    "# 3. Nombre de transactions par plage de montants\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_with_bins = df_with_amount.withColumn(\n",
    "    \"amount_range\",\n",
    "    when(col(\"Amount\") < 10, \"0-10\")\n",
    "    .when(col(\"Amount\") < 100, \"10-100\")\n",
    "    .when(col(\"Amount\") < 1000, \"100-1000\")\n",
    "    .otherwise(\"1000+\")\n",
    ")\n",
    "\n",
    "df_with_bins.groupBy(\"label\", \"amount_range\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"label\", \"amount_range\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96f30493-71f8-45ab-bab3-67210df127a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Statistiques Montant par classe ===\n",
      "+-----+------+----------+----------+----------+----------+-------------+\n",
      "|label| count|avg_amount|std_amount|min_amount|max_amount| total_amount|\n",
      "+-----+------+----------+----------+----------+----------+-------------+\n",
      "|    0|227645|     88.34|    249.57|       0.0|  25691.16|2.010914456E7|\n",
      "|    1|   400|     125.6|    258.35|       0.0|   2125.87|     50240.08|\n",
      "+-----+------+----------+----------+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# b) Statistiques sur le montant (Section 3.3 & 3.4)\n",
    "# Comme tu as un vecteur features, on extrait le montant\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col, avg, stddev, min, max, sum\n",
    "\n",
    "# Convertir le vecteur en tableau\n",
    "df_array = train_df.withColumn(\"features_array\", vector_to_array(col(\"features\")))\n",
    "\n",
    "# Extraire la colonne Amount (position 29 selon ton TP)\n",
    "df_with_amount = df_array.withColumn(\"Amount\", col(\"features_array\").getItem(29))\n",
    "\n",
    "# Cr√©er une nouvelle vue\n",
    "df_with_amount.createOrReplaceTempView(\"transactions_with_amount\")\n",
    "\n",
    "# Statistiques par classe (comme Section 3.4)\n",
    "print(\"\\n=== Statistiques Montant par classe ===\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT label,\n",
    "           COUNT(*) as count,\n",
    "           ROUND(AVG(Amount), 2) as avg_amount,\n",
    "           ROUND(STDDEV(Amount), 2) as std_amount,\n",
    "           ROUND(MIN(Amount), 2) as min_amount,\n",
    "           ROUND(MAX(Amount), 2) as max_amount,\n",
    "           ROUND(SUM(Amount), 2) as total_amount\n",
    "    FROM transactions_with_amount\n",
    "    GROUP BY label\n",
    "    ORDER BY label\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "369b029f-b2ae-4c8d-8566-04e0a94f6497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transactions suspectes (montant √©lev√©) ===\n",
      "+-----+-------+-----+\n",
      "|label| Amount|count|\n",
      "+-----+-------+-----+\n",
      "|    1|2125.87|    1|\n",
      "|    1|1504.93|    1|\n",
      "|    1|1402.16|    1|\n",
      "|    1|1389.56|    1|\n",
      "|    1|1354.25|    1|\n",
      "|    1| 1335.0|    1|\n",
      "|    1|1218.89|    1|\n",
      "+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Transactions suspectes (montant √©lev√©) ===\")\n",
    "# Filtrer les transactions frauduleuses avec montant > 1000\n",
    "spark.sql(\"\"\"\n",
    "    SELECT label, Amount, COUNT(*) as count\n",
    "    FROM transactions_with_amount\n",
    "    WHERE label = 1 AND Amount > 1000\n",
    "    GROUP BY label, Amount\n",
    "    ORDER BY Amount DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29fb6cb7-6f04-4f01-b011-b7845ac44ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HISTOGRAMME : Distribution des montants par classe\n",
      "Distribution des montants par classe:\n",
      "+-------------+------+---------------+---------------+\n",
      "|plage_montant|classe|nb_transactions|moyenne_montant|\n",
      "+-------------+------+---------------+---------------+\n",
      "|         0-10|     0|          77750|            3.7|\n",
      "|         0-10|     1|            203|           1.73|\n",
      "|        10-50|     0|          73973|          25.13|\n",
      "|        10-50|     1|             47|          26.68|\n",
      "|       50-100|     0|          30061|          71.81|\n",
      "|       50-100|     1|             41|          87.31|\n",
      "|      100-500|     0|          38250|         208.45|\n",
      "|      100-500|     1|             79|         238.58|\n",
      "|     500-1000|     0|           5167|         676.51|\n",
      "|     500-1000|     1|             23|         690.26|\n",
      "|        1000+|     0|           2444|        1773.93|\n",
      "|        1000+|     1|              7|        1475.81|\n",
      "+-------------+------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä HISTOGRAMME : Distribution des montants par classe\")\n",
    "\n",
    "# Utiliser df_with_amount que tu as d√©j√† cr√©√©\n",
    "df_with_amount.createOrReplaceTempView(\"transactions_with_amount\")\n",
    "\n",
    "# Histogramme simple\n",
    "histogram_simple = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  CASE \n",
    "    WHEN Amount < 10 THEN '0-10'\n",
    "    WHEN Amount < 50 THEN '10-50'\n",
    "    WHEN Amount < 100 THEN '50-100'\n",
    "    WHEN Amount < 500 THEN '100-500'\n",
    "    WHEN Amount < 1000 THEN '500-1000'\n",
    "    ELSE '1000+'\n",
    "  END as plage_montant,\n",
    "  label as classe,\n",
    "  COUNT(*) as nb_transactions,\n",
    "  ROUND(AVG(Amount), 2) as moyenne_montant\n",
    "FROM transactions_with_amount\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN Amount < 10 THEN '0-10'\n",
    "    WHEN Amount < 50 THEN '10-50'\n",
    "    WHEN Amount < 100 THEN '50-100'\n",
    "    WHEN Amount < 500 THEN '100-500'\n",
    "    WHEN Amount < 1000 THEN '500-1000'\n",
    "    ELSE '1000+'\n",
    "  END,\n",
    "  label\n",
    "ORDER BY \n",
    "  CASE \n",
    "    WHEN plage_montant = '0-10' THEN 1\n",
    "    WHEN plage_montant = '10-50' THEN 2\n",
    "    WHEN plage_montant = '50-100' THEN 3\n",
    "    WHEN plage_montant = '100-500' THEN 4\n",
    "    WHEN plage_montant = '500-1000' THEN 5\n",
    "    ELSE 6\n",
    "  END,\n",
    "  label\n",
    "\"\"\")\n",
    "\n",
    "print(\"Distribution des montants par classe:\")\n",
    "histogram_simple.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3320a614-4c21-4fc8-b1ae-30f10fefbcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HISTOGRAMME 2D : MONTANT vs CLASSE DE FRAUDE\n",
      "Histogramme 2D - Distribution Montant vs Classe:\n",
      "+-------------+------+-------------------+-------------+-----------+-----------+\n",
      "|montant_plage|classe|nombre_transactions|montant_moyen|montant_min|montant_max|\n",
      "+-------------+------+-------------------+-------------+-----------+-----------+\n",
      "|         0-10|     0|              77750|          3.7|        0.0|       9.99|\n",
      "|         0-10|     1|                203|         1.73|        0.0|       9.99|\n",
      "|        10-50|     0|              73973|        25.13|       10.0|      49.99|\n",
      "|        10-50|     1|                 47|        26.68|       10.7|      45.64|\n",
      "|       50-100|     0|              30061|        71.81|       50.0|      99.99|\n",
      "|       50-100|     1|                 41|        87.31|       50.0|      99.99|\n",
      "|      100-500|     0|              38250|       208.45|      100.0|     499.99|\n",
      "|      100-500|     1|                 79|       238.58|      101.5|     489.71|\n",
      "|     500-1000|     0|               5167|       676.51|      500.0|      999.9|\n",
      "|     500-1000|     1|                 23|       690.26|     512.25|     996.27|\n",
      "|        1000+|     0|               2444|      1773.93|     1000.0|   25691.16|\n",
      "|        1000+|     1|                  7|      1475.81|    1218.89|    2125.87|\n",
      "+-------------+------+-------------------+-------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä HISTOGRAMME 2D : MONTANT vs CLASSE DE FRAUDE\")\n",
    "\n",
    "# Cr√©er un histogramme 2D avec groupBy\n",
    "histogram_2d = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  -- Axe X : Plages de montant\n",
    "  CASE \n",
    "    WHEN Amount < 10 THEN '0-10'\n",
    "    WHEN Amount < 50 THEN '10-50'\n",
    "    WHEN Amount < 100 THEN '50-100'\n",
    "    WHEN Amount < 500 THEN '100-500'\n",
    "    WHEN Amount < 1000 THEN '500-1000'\n",
    "    ELSE '1000+'\n",
    "  END as montant_plage,\n",
    "  \n",
    "  -- Axe Y : Classe (0=normal, 1=fraude)\n",
    "  label as classe,\n",
    "  \n",
    "  -- Valeur : Nombre de transactions\n",
    "  COUNT(*) as nombre_transactions,\n",
    "  \n",
    "  -- Statistiques suppl√©mentaires\n",
    "  ROUND(AVG(Amount), 2) as montant_moyen,\n",
    "  ROUND(MIN(Amount), 2) as montant_min,\n",
    "  ROUND(MAX(Amount), 2) as montant_max\n",
    "  \n",
    "FROM transactions_with_amount\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN Amount < 10 THEN '0-10'\n",
    "    WHEN Amount < 50 THEN '10-50'\n",
    "    WHEN Amount < 100 THEN '50-100'\n",
    "    WHEN Amount < 500 THEN '100-500'\n",
    "    WHEN Amount < 1000 THEN '500-1000'\n",
    "    ELSE '1000+'\n",
    "  END,\n",
    "  label\n",
    "ORDER BY \n",
    "  CASE \n",
    "    WHEN montant_plage = '0-10' THEN 1\n",
    "    WHEN montant_plage = '10-50' THEN 2\n",
    "    WHEN montant_plage = '50-100' THEN 3\n",
    "    WHEN montant_plage = '100-500' THEN 4\n",
    "    WHEN montant_plage = '500-1000' THEN 5\n",
    "    ELSE 6\n",
    "  END,\n",
    "  classe\n",
    "\"\"\")\n",
    "\n",
    "print(\"Histogramme 2D - Distribution Montant vs Classe:\")\n",
    "histogram_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff72e06-fe60-46e4-a022-de0780a93712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HISTOGRAMME 2D RAPIDE\n",
      "Histogramme 2D simple:\n",
      "+----------------+------+------+-------+\n",
      "|          taille|  type|nombre|moyenne|\n",
      "+----------------+------+------+-------+\n",
      "|    Petit (<100)|FRAUDE|   291|  17.82|\n",
      "|    Petit (<100)|NORMAL|181784|  23.68|\n",
      "|Moyen (100-1000)|FRAUDE|   102| 340.43|\n",
      "|Moyen (100-1000)|NORMAL| 43417| 264.16|\n",
      "|   Grand (>1000)|FRAUDE|     7|1475.81|\n",
      "|   Grand (>1000)|NORMAL|  2444|1773.93|\n",
      "+----------------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üöÄ COMMANDE RAPIDE 2D\n",
    "\n",
    "print(\"\\nüìä HISTOGRAMME 2D RAPIDE\")\n",
    "\n",
    "quick_2d = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  -- Dimension X: Montant (3 cat√©gories)\n",
    "  CASE \n",
    "    WHEN Amount < 100 THEN 'Petit (<100)'\n",
    "    WHEN Amount < 1000 THEN 'Moyen (100-1000)'\n",
    "    ELSE 'Grand (>1000)'\n",
    "  END as taille,\n",
    "  \n",
    "  -- Dimension Y: Type\n",
    "  CASE \n",
    "    WHEN label = 1 THEN 'FRAUDE'\n",
    "    ELSE 'NORMAL'\n",
    "  END as type,\n",
    "  \n",
    "  -- Valeur\n",
    "  COUNT(*) as nombre,\n",
    "  ROUND(AVG(Amount), 2) as moyenne\n",
    "  \n",
    "FROM transactions_with_amount\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN Amount < 100 THEN 'Petit (<100)'\n",
    "    WHEN Amount < 1000 THEN 'Moyen (100-1000)'\n",
    "    ELSE 'Grand (>1000)'\n",
    "  END,\n",
    "  CASE \n",
    "    WHEN label = 1 THEN 'FRAUDE'\n",
    "    ELSE 'NORMAL'\n",
    "  END\n",
    "ORDER BY \n",
    "  CASE \n",
    "    WHEN taille = 'Petit (<100)' THEN 1\n",
    "    WHEN taille = 'Moyen (100-1000)' THEN 2\n",
    "    ELSE 3\n",
    "  END,\n",
    "  CASE \n",
    "    WHEN type = 'FRAUDE' THEN 1\n",
    "    ELSE 2\n",
    "  END\n",
    "\"\"\")\n",
    "\n",
    "print(\"Histogramme 2D simple:\")\n",
    "quick_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58806e-8e03-422b-b12a-40d4b3eba9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
