import os
import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, current_timestamp
from pyspark.sql.types import StructType, StructField, DoubleType
from pyspark.ml import PipelineModel

# --- Configuration ---
APP_NAME = "FraudDetectionStreaming"
INPUT_DIR = "file:///home/hadoop/streaming_input"           # AJOUT DE file://
CHECKPOINT_LOCATION = "file:///home/hadoop/streaming_checkpoint" # AJOUT DE file://
MODEL_PATH = "file:///tmp/spark_models/fraude_gbt_final_1767574836" 


# CHEMIN FINAL CORRIG√â ET V√âRIFI√â DU MOD√àLE
MODEL_PATH = "file:///tmp/spark_models/fraude_gbt_final_1767574836" 
# --- Sch√©ma des Donn√©es de Transaction ---
data_schema = StructType([
    StructField("Time", DoubleType(), True),
    StructField("V1", DoubleType(), True),
    StructField("V2", DoubleType(), True),
    StructField("V3", DoubleType(), True),
    StructField("V4", DoubleType(), True),
    StructField("V5", DoubleType(), True),
    StructField("V6", DoubleType(), True),
    StructField("V7", DoubleType(), True),
    StructField("V8", DoubleType(), True),
    StructField("V9", DoubleType(), True),
    StructField("V10", DoubleType(), True),
    StructField("V11", DoubleType(), True),
    StructField("V12", DoubleType(), True),
    StructField("V13", DoubleType(), True),
    StructField("V14", DoubleType(), True),
    StructField("V15", DoubleType(), True),
    StructField("V16", DoubleType(), True),
    StructField("V17", DoubleType(), True),
    StructField("V18", DoubleType(), True),
    StructField("V19", DoubleType(), True),
    StructField("V20", DoubleType(), True),
    StructField("V21", DoubleType(), True),
    StructField("V22", DoubleType(), True),
    StructField("V23", DoubleType(), True),
    StructField("V24", DoubleType(), True),
    StructField("V25", DoubleType(), True),
    StructField("V26", DoubleType(), True),
    StructField("V27", DoubleType(), True),
    StructField("V28", DoubleType(), True),
    StructField("Amount", DoubleType(), True)
])


def start_streaming_job():
    """D√©marre le job de Spark Structured Streaming pour la d√©tection de fraude."""

    # Initialisation de la session Spark
    spark = SparkSession.builder \
        .appName(APP_NAME) \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("ERROR")
    print(f"Spark Session (version {spark.version}) d√©marr√©e pour le streaming.")

    # 1. Charger le mod√®le ML entra√Æn√©
    try:
        # La v√©rification de placeholder a √©t√© retir√©e pour √©viter l'erreur de syntaxe
        model = PipelineModel.load(MODEL_PATH) 
        print(f"Mod√®le ML charg√© avec succ√®s depuis {MODEL_PATH}")
    except Exception as e:
        print(f"Erreur FATALE lors du chargement du mod√®le. V√©rifiez le chemin : {e}")
        sys.exit(1)
        
    # 2. D√©finir la source de streaming (Lecture de fichiers CSV entrants)
    raw_stream = spark.readStream.schema(data_schema)
    raw_stream = raw_stream.option("maxFilesPerTrigger", 1)
    raw_stream = raw_stream.option("header", "true")
    raw_stream = raw_stream.csv(INPUT_DIR)
        
    print(f"D√©marrage de la lecture en streaming √† partir de {INPUT_DIR}...")

    # 3. Application du mod√®le √† la vol√©e (le 'transform' est une op√©ration de streaming valide)
    prediction_stream = model.transform(raw_stream)

    # 4. Pr√©parer le r√©sultat pour la sortie
    output_stream = prediction_stream.withColumn(
        "fraud_status", 
        when(col("prediction") == 1.0, "üî¥ FRAUDE D√âTECT√âE")
        .otherwise("üü¢ L√©gitime")
    ).select(
        col("Time"),
        col("Amount"),
        col("prediction").alias("IsFraud"),
        col("fraud_status"),
        current_timestamp().alias("processing_time")
    )
    
    # 5. D√©finir le Sink (destination : la console pour le monitoring)
    query = output_stream.writeStream \
        .outputMode("append") \
        .format("console") \
        .trigger(processingTime="5 seconds") \
        .option("checkpointLocation", CHECKPOINT_LOCATION) \
        .start()

    print("\n---------------------------------------------------------------------")
    print(f"Pipeline de d√©tection de fraude en temps r√©el d√©marr√©, surveillant : {INPUT_DIR}")
    print("Pour simuler l'arriv√©e de donn√©es, copiez des lignes de votre CSV dans un nouveau fichier (.csv) dans ce r√©pertoire.")
    print("Appuyez sur Ctrl+C pour arr√™ter le job de streaming.")
    print("---------------------------------------------------------------------")
    
    query.awaitTermination()

if __name__ == "__main__":
    start_streaming_job()